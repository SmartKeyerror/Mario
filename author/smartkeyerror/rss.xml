<?xml version="1.0" encoding="UTF-8" ?>

<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
<channel>
   
      <title>smartkeyerror.com/</title>
   
   <link>https://smartkeyerror.com</link>
   <description>Keep coding, Keep curiosity</description>
   <language>en-uk</language>
   <managingEditor> </managingEditor>
   <atom:link href="rss" rel="self" type="application/rss+xml" />
   
	<item>
	  <title>MySQL中的悲观锁与常见的死锁场景</title>
	  <link>//MySQL-Lock</link>
	  <author></author>
	  <pubDate>2019-09-18T21:39:25+00:00</pubDate>
	  <guid>//MySQL-Lock</guid>
	  <description><![CDATA[
	     <p>在MySQL中， 锁机制是并发条件下保护数据一致性与稳定性的一个非常重要的机制， 并且事务的实现也依赖于于锁机制。 其锁定的数据不单包括数据行记录， 同时也包括缓冲池中的LRU列表数据、日志数据等。 悲观锁(FOR UPDATE)则是日常开发中使用最多的一种锁， 但是， 由于事务隔离级别的多样性导致了悲观锁在使用时常常会有不同的表现， 死锁在程序员稍不注意时就会发生。</p>

<!---more--->

<h4 id="1-悲观锁概述">1. 悲观锁概述</h4>
<p>在通用的程序设计语言中， 锁通常是基于某一个对象， 或者是一组对象而言。 在Python、Java和Golang中， 分别提供了<code class="highlighter-rouge">threading.Lock</code>、<code class="highlighter-rouge">synchronized</code>以及<code class="highlighter-rouge">sync.Mutex</code>互斥所机制。 而数据库要更为特殊一些， 其原因就在于我们所管理的不是一个个的对象， 而是一行行的数据。</p>

<p>InnoDB存储引擎支持的最小锁粒度为行锁， 可以通过在事务中执行<code class="highlighter-rouge">SELECT .. FOR UPDATE</code>为某一行或者是多行数据添加互斥锁。 锁的生命周期完全由InnoDB管理， 当事务成功提交或者是失败回滚时， 互斥锁则自动释放。</p>

<p>需要注意的一点是， 互斥锁必须在事务中执行才会生效。 当<code class="highlighter-rouge">autocommit</code>为<code class="highlighter-rouge">ON</code>时， 需要显示的使用<code class="highlighter-rouge">BEGIN</code>开启事务， 而后对数据添加互斥锁。</p>

<p>在程序设计语言中， 锁的目的是串行化修改、删除操作， InnoDB中的互斥锁有着同样的目的。 但是， 由于事务隔离级别的分类， 使得互斥锁的行为变得复杂许多。 其中最让人感到迷惑的就是为了解决幻读问题所添加的<code class="highlighter-rouge">GAP Lock</code>。</p>

<h4 id="2-事务隔离级别概述">2. 事务隔离级别概述</h4>

<p>不同的事务隔离级别， 悲观锁会产生不同的行为。 所以， 理解事务隔离级别是理解悲观锁的第一步。</p>

<p>InnoDB事务隔离级别从低到高依次为未提交读(READ UNCOMMITED)， 提交读(READ COMMITED)， 可重复读(READ REPEATABLE)以及串行化(SERIALIZABLE)。</p>

<p>未提交读指的是事务B可以读取到事务A未提交的数据， 此时若事务A回滚， 那么事务B读到的就是错误数据， 也称为脏数据。 该读取行为有时也会被称为脏读， 因为未提交读会导致脏读的问题， 从而导致数据混乱， 所以该事务隔离级别基本不会被使用。</p>

<p><img src="https://smartkeyerror.oss-cn-shenzhen.aliyuncs.com/jojo/system-design/mysql/lock/read-uncommitted-with-dirty-data.png" alt="" /></p>

<p>提交读是指在执行事务B时， 可以读取到事务A提交到的数据， 未提交的数据不可读取。 提交读解决了脏读的问题， 读取到的数据一定是已经持久化至磁盘的数据， 但是会出现同一条SQL语句在执行时出现不一致的情况。 例如事务A、B先后开始执行， 事务A首先读取row-1的内容， 而此时事务B对row-1的内容修改并提交， 此时事务A再次读取row-1数据， 发现其已经发生改变， 而该变化并不是事务A自身进行的。 这种情况又称为不可重复读。</p>

<p><img src="https://smartkeyerror.oss-cn-shenzhen.aliyuncs.com/jojo/system-design/mysql/lock/Read-Committed.png" alt="" /></p>

<p>可重复读， 顾名思义， 解决了提交读的不可重复读问题， 使得事务在读取同一行数据时， 结果并不会因为其它事务的执行而发生改变， 数据发生的修改行为在整个事务内是可以自恰的。 但是并没有解决幻读的问题， 幻读是指其余事务在某一个区间内插入数据， 而非修改数据， 此时事务也会读取到这部分插入的数据。 InnoDB借助MVCC(多版本并发控制)以及锁机制来解决幻读问题。</p>

<p>MVCC即在数据中添加版本号， 数据插入时会有初始版本号， 在修改、删除时更新版本号。</p>

<p><img src="https://smartkeyerror.oss-cn-shenzhen.aliyuncs.com/jojo/system-design/mysql/lock/Repeatable-Read.png" alt="" /></p>

<p>串行化指事务串行化执行， 自然就不会有出现上述出现的脏读、不可重复读以及幻读了。 一个很重要的事实是， 串行化的事务隔离级别执行效率并不会比可重复读事务隔离级别差很多。 同样的， 提交读执行效率也不会比可重复读执行效率高多少， 所以在优化数据库时， 事务隔离级别不应该是效率优化目标， 而是业务优化目标。</p>

<h4 id="3-mysql中的锁">3. MySQL中的锁</h4>

<p>使用<code class="highlighter-rouge">FOR UPDATE</code>对某一行或者是多行数据添加的锁， 其实是由MySQL更细粒度的锁组合而成的， 不同的事务隔离级别有不同的组合方式。</p>

<p>在InnoDB存储引擎中， 存在3种行锁的算法， 其分别为:</p>
<ul>
  <li>Record Lock: 单个行记录上的锁，聚集索引及辅助索引均会添加锁。</li>
  <li>Gap Lock: 间隙锁， 锁定一个范围， 但不包含行记录本身。</li>
  <li>Next-Key Lock: Record Lock + Gap Lock，锁定行记录本身并且锁定一个范围。</li>
</ul>

<p>下面用一个实际的例子来解释Record Lock以及Gap Lock。 首先表结构定义如下:</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">lock_test</span> <span class="p">(</span>
  <span class="n">id</span> <span class="n">int</span><span class="p">(</span><span class="mi">11</span><span class="p">)</span> <span class="k">NOT</span> <span class="k">NULL</span> <span class="n">AUTO_INCREMENT</span><span class="p">,</span>
  <span class="n">a</span> <span class="n">varchar</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span> <span class="k">NOT</span> <span class="k">NULL</span><span class="p">,</span>
  <span class="k">PRIMARY</span> <span class="k">KEY</span> <span class="p">(</span><span class="n">id</span><span class="p">),</span>
  <span class="k">KEY</span> <span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="p">)</span> <span class="n">ENGINE</span><span class="o">=</span><span class="n">InnoDB</span> <span class="k">DEFAULT</span> <span class="n">CHARSET</span><span class="o">=</span><span class="n">latin1</span><span class="p">;</span>

<span class="c1">-- 插入部分测试数据</span>
<span class="k">insert</span> <span class="k">into</span> <span class="n">lock_test</span> <span class="p">(</span><span class="n">a</span><span class="p">)</span> <span class="k">values</span> <span class="p">(</span><span class="nv">"1"</span><span class="p">);</span>
<span class="k">insert</span> <span class="k">into</span> <span class="n">lock_test</span> <span class="p">(</span><span class="n">a</span><span class="p">)</span> <span class="k">values</span> <span class="p">(</span><span class="nv">"3"</span><span class="p">);</span>
<span class="k">insert</span> <span class="k">into</span> <span class="n">lock_test</span> <span class="p">(</span><span class="n">a</span><span class="p">)</span> <span class="k">values</span> <span class="p">(</span><span class="nv">"5"</span><span class="p">);</span>
<span class="k">insert</span> <span class="k">into</span> <span class="n">lock_test</span> <span class="p">(</span><span class="n">a</span><span class="p">)</span> <span class="k">values</span> <span class="p">(</span><span class="nv">"8"</span><span class="p">);</span>
</code></pre></div></div>

<p>接着执行下面的语句:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: left">时间</th>
      <th style="text-align: left">会话A</th>
      <th style="text-align: left">会话B</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left">1</td>
      <td style="text-align: left">BEGIN;</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: left">2</td>
      <td style="text-align: left">SELECT * FROM lock_test <br /> WHERE a = “5” FOR UPDATE;</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: left">3</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">BEGIN;</td>
    </tr>
    <tr>
      <td style="text-align: left">4</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">INSERT INTO lock_test (a) VALUES (“4”); <br /> 阻塞，等待会话A事务的提交</td>
    </tr>
    <tr>
      <td style="text-align: left">5</td>
      <td style="text-align: left">COMMIT;</td>
      <td style="text-align: left">Query OK, 1 row affected (6.87 sec)</td>
    </tr>
  </tbody>
</table>

<p>尽管列<code class="highlighter-rouge">a</code>添加了辅助索引， 但是在对该列使用<code class="highlighter-rouge">FOR UPDATE</code>添加悲观锁时， 仍然会出现其它列被锁定的现象。 这是因为<code class="highlighter-rouge">a = "5"</code>该行数据不仅被添加了Record Lock， 并且也添加了Gap Lock， 其目的就是为了解决幻读问题， 前提是当前事务隔离级别为REPEATABLE READ。</p>

<p>在列<code class="highlighter-rouge">a</code>的辅助索引中， 值”5”之前的值为”3”， 故存在(3, 5)这个间隙， 所以在插入值”4”时， InnoDB为了杜绝幻读现象的发生， 使得只有在会话A事务提交时才允许插入操作的进行。 另外一点需要注意的是， 当查询的索引具有唯一属性时， InnoDB存储引擎会对Next-Key Lock进行优化， 将其降级为Record Lock， 即仅锁住索引本身， 而不锁定一个范围。</p>

<blockquote>
  <p>For a unique index with a unique search condition, InnoDB locks only the index record found, not the gap before it.</p>
</blockquote>

<h4 id="4-锁与事务之间的关联">4. 锁与事务之间的关联</h4>

<p>前面提到了Gap Lock的存在主要是为了解决幻读问题的发生， 而在READ COMMITTED事务隔离级别中， 只解决了脏读问题， 所以说， 在该事务隔离级别下， <code class="highlighter-rouge">FOR UPDATE</code>仅会添加Record Lock， 并不会添加Gap Lock。</p>

<blockquote>
  <p>For locking reads (SELECT with FOR UPDATE or FOR SHARE), UPDATE statements, and DELETE statements, InnoDB locks only index records, not the gaps before them.</p>
</blockquote>

<blockquote>
  <p>Because gap locking is disabled, phantom problems may occur, as other sessions can insert new rows into the gaps</p>
</blockquote>

<p>此外， 如果用户通过索引查询一个值， 并在其之上添加排它锁， 当查询的值不存在时， READ COMMITTED与REPEATABLE READ两个事务隔离级别所产生的行为同样存在差异， 一个最直观的差异就是REPEATABLE READ在并发条件下会产生死锁， 而READ COMMITTED则不会。</p>

<p>READ COMMITTED事务隔离级别:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: left">时间</th>
      <th style="text-align: left">会话A</th>
      <th style="text-align: left">会话B</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left">1</td>
      <td style="text-align: left">BEGIN;</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: left">2</td>
      <td style="text-align: left">SELECT * FROM lock_test <br /> WHERE a = “100” FOR UPDATE;</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: left">3</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">BEGIN;</td>
    </tr>
    <tr>
      <td style="text-align: left">4</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">SELECT * FROM lock_test <br /> WHERE a = “100” FOR UPDATE; <br /> 不会被阻塞</td>
    </tr>
    <tr>
      <td style="text-align: left">5</td>
      <td style="text-align: left">INSERT INTO lock_test (a) VALUES (“100”); <br /> 不会被阻塞</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: left">6</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">INSERT INTO lock_test (a) VALUES (“100”); <br /> 不会被阻塞</td>
    </tr>
    <tr>
      <td style="text-align: left">7</td>
      <td style="text-align: left">COMMIT;</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: left">8</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">COMMIT;</td>
    </tr>
  </tbody>
</table>

<p>所以说， 当事务隔离级别为READ COMMITTED时， 无法使用Next-Key Lock来帮助我们实现类似于<code class="highlighter-rouge">update_or_create</code>或者是<code class="highlighter-rouge">get_or_create</code>等方法， 因为在并发条件下会造成重复数据创建， 除非表中存在唯一索引。 这也是Django框架官网中所提到的Multiply records问题。 感兴趣的小伙伴可访问官网获取更多详细内容:</p>

<blockquote>
  <p>https://docs.djangoproject.com/en/2.2/ref/models/querysets/#get-or-create</p>
</blockquote>

<p>REPEATABLE READ事务隔离级别:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: left">时间</th>
      <th style="text-align: left">会话A</th>
      <th style="text-align: left">会话B</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left">1</td>
      <td style="text-align: left">BEGIN;</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: left">2</td>
      <td style="text-align: left">SELECT * FROM lock_test <br /> WHERE a = “200” FOR UPDATE;</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: left">3</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">BEGIN;</td>
    </tr>
    <tr>
      <td style="text-align: left">4</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">SELECT * FROM lock_test <br /> WHERE a = “200” FOR UPDATE; <br /> 不会被阻塞</td>
    </tr>
    <tr>
      <td style="text-align: left">5</td>
      <td style="text-align: left">INSERT INTO lock_test (a) VALUES (“200”); <br /> 阻塞, 等待事务B的结束</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: left">6</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">INSERT INTO lock_test (a) VALUES (“200”); <br /> ERROR 1213 (40001): Deadlock found when trying to get lock; try restarting transaction，死锁发生</td>
    </tr>
  </tbody>
</table>

<p>当在REPEATABLE READ事务隔离级别级别下实现<code class="highlighter-rouge">get_or_create</code>方法时，会产生死锁问题， 原因就在于锁定的记录并不存在， 多个事务可同时对其添加悲观锁， 但是插入语句的执行位置是不确定的， 所以就会有死锁问题的出现。解决此类问题的一个方法就是使用指数退避方式的重试。</p>

<h4 id="5-死锁">5. 死锁</h4>

<p>通常来讲， 如果我们的SQL执行计划较为简单， 几乎所有的执行均为单条语句执行时， 死锁基本与我们无关。 但是当执行计划稍加复杂， 事务执行的语句较多时， 就会出现死锁问题。 一个最经典的死锁场景即为AB-BA死锁。</p>

<table>
  <thead>
    <tr>
      <th style="text-align: left">时间</th>
      <th style="text-align: left">会话A</th>
      <th style="text-align: left">会话B</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left">1</td>
      <td style="text-align: left">BEGIN;</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: left">2</td>
      <td style="text-align: left">SELECT * FROM lock_test <br /> WHERE a = “200” FOR UPDATE;</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: left">3</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">BEGIN;</td>
    </tr>
    <tr>
      <td style="text-align: left">4</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">SELECT * FROM lock_test <br /> WHERE a = “400” FOR UPDATE;</td>
    </tr>
    <tr>
      <td style="text-align: left">5</td>
      <td style="text-align: left">SELECT * FROM lock_test <br /> WHERE a = “400” FOR UPDATE<br /> 阻塞, 等待事务B的结束</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: left">6</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">SELECT * FROM lock_test <br /> WHERE a = “200” FOR UPDATE; <br /> ERROR 1213 (40001): Deadlock found when trying to get lock; try restarting transaction，死锁发生</td>
    </tr>
  </tbody>
</table>

<p>当MySQL检测到死锁时， 会根据其事务权重选择性的回滚其中一个事务。 但是， 权重的判定完全由MySQL决定， 业务系统无法人为的干预， 如果某一个事务在业务系统中非常重要， 但是MySQL却回滚了该事务， 而业务系统仅捕捉了该异常并向外扩散的话， 并不是我们期望的结果。 所以， 在绝大多数场景下， 指数退避的重试策略要更好一些。 或者对于关键性的业务逻辑， 使用Redis等消息队列进行串行化操作。</p>

<p>另外一个死锁场景则是上一小节中我们所见到的并发执行<code class="highlighter-rouge">if not exist then create</code>模式所带来的死锁问题， 该模式在业务场景下其实非常常见。</p>

<h4 id="reference">Reference</h4>
<ul>
  <li>https://dev.mysql.com/doc/refman/8.0/en/innodb-transaction-isolation-levels.html</li>
  <li>https://dev.mysql.com/doc/refman/8.0/en/innodb-locking.html</li>
  <li>https://dev.mysql.com/doc/refman/8.0/en/innodb-deadlocks.html</li>
</ul>

	  ]]></description>
	</item>

	<item>
	  <title>MySQL中的联合索引与覆盖索引</title>
	  <link>//MySQL-union-index-and-cover-index</link>
	  <author></author>
	  <pubDate>2019-09-01T21:39:25+00:00</pubDate>
	  <guid>//MySQL-union-index-and-cover-index</guid>
	  <description><![CDATA[
	     <p>在上一篇文章中， 通过解析InnoDB存储引擎的<code class="highlighter-rouge">.ibd</code>数据存储文件得到了数据与索引的真实组织方式: 数据通过聚集索引在逻辑上连续存放， 二级索引保存数据主键ID(Row ID)， 多棵B+Tree组合起来提供高效的索引数据查询。 除辅助索引(二级索引)外， 联合索引与覆盖索引在日常中也会经常用到。</p>

<!---more--->

<h4 id="1-联合索引">1. 联合索引</h4>
<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">union_test</span> <span class="p">(</span>
	<span class="n">id</span> <span class="n">int</span><span class="p">(</span><span class="mi">11</span><span class="p">)</span> <span class="k">NOT</span> <span class="k">NULL</span> <span class="n">AUTO_INCREMENT</span><span class="p">,</span>
	<span class="n">user_id</span> <span class="n">varchar</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span> <span class="k">NOT</span> <span class="k">NULL</span><span class="p">,</span>
	<span class="n">order_id</span> <span class="n">varchar</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span> <span class="k">NOT</span> <span class="k">NULL</span><span class="p">,</span>
	<span class="k">PRIMARY</span> <span class="k">KEY</span> <span class="p">(</span><span class="n">id</span><span class="p">),</span>
	<span class="k">KEY</span> <span class="n">ix_union_order_id_user_id</span> <span class="p">(</span><span class="n">user_id</span><span class="p">,</span> <span class="n">order_id</span><span class="p">)</span>
<span class="p">)</span> <span class="n">ENGINE</span><span class="o">=</span><span class="n">InnoDB</span> <span class="k">DEFAULT</span> <span class="n">CHARSET</span><span class="o">=</span><span class="n">LATIN1</span><span class="p">;</span>

<span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">union_test</span> <span class="p">(</span><span class="n">user_id</span><span class="p">,</span> <span class="n">order_id</span><span class="p">)</span> <span class="k">VALUES</span> <span class="p">(</span><span class="nv">"0000"</span><span class="p">,</span> <span class="nv">"A0000"</span><span class="p">);</span>
<span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">union_test</span> <span class="p">(</span><span class="n">user_id</span><span class="p">,</span> <span class="n">order_id</span><span class="p">)</span> <span class="k">VALUES</span> <span class="p">(</span><span class="nv">"0000"</span><span class="p">,</span> <span class="nv">"A0001"</span><span class="p">);</span>
<span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">union_test</span> <span class="p">(</span><span class="n">user_id</span><span class="p">,</span> <span class="n">order_id</span><span class="p">)</span> <span class="k">VALUES</span> <span class="p">(</span><span class="nv">"0001"</span><span class="p">,</span> <span class="nv">"A0003"</span><span class="p">);</span>
<span class="p">...</span>
</code></pre></div></div>

<p>在创建表结构以及插入部分测试数据之后， 我们依然使用<code class="highlighter-rouge">hexdump -C</code>来对<code class="highlighter-rouge">.ibd</code>文件进行分析， 从最基本的数据存储结构中更能够发现联合索引的存储特点。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>00010070  73 75 70 72 65 6d 75 6d  03 04 00 00 10 00 36 30  |supremum......60|
00010080  30 35 38 41 31 34 80 00  00 01 03 04 07 00 18 05  |058A14..........|
00010090  e2 30 30 33 36 41 32 30  80 00 00 02 03 04 08 00  |.0036A20........|
000100a0  20 00 fb 30 30 34 33 41  31 33 80 00 00 03 03 04  | ..0043A13......|
000100b0  00 00 28 01 67 30 30 35  39 41 32 31 80 00 00 04  |..<span class="o">(</span>.g0059A21....|
000100c0  03 04 08 00 30 02 65 30  30 34 39 41 38 39 80 00  |....0.e0049A89..|
000100d0  00 05 03 04 00 00 38 01  1f 30 30 35 31 41 35 34  |......8..0051A54|
000100e0  80 00 00 06 02 04 06 00  40 05 76 30 30 32 33 41  |........@.v0023A|
000100f0  36 80 00 00 07 03 04 00  00 48 02 0c 30 30 30 31  |6........H..0001|
00010100  41 35 30 80 00 00 08 03  04 00 00 50 06 19 30 30  |A50........P..00|
00010110  31 35 41 39 31 80 00 00  09 03 04 00 00 58 ff 83  |15A91........X..|
00010120  30 30 34 32 41 37 32 80  00 00 0a 03 04 00 00 60  |0042A72........<span class="sb">`</span>|
00010130  01 56 30 30 33 38 41 39  35 80 00 00 0b 03 04 00  |.V0038A95.......|
00010140  00 68 03 4f 30 30 32 39  41 39 37 80 00 00 0c 03  |.h.O0029A97.....|
00010150  04 05 00 70 05 41 30 30  35 37 41 31 31 80 00 00  |...p.A0057A11...|
00010160  0d 03 04 00 00 78 02 c0  30 30 31 39 41 35 32 80  |.....x..0019A52.|
</code></pre></div></div>

<p>直接截取部分的联合索引内容进行分析， 索引数据从<code class="highlighter-rouge">00010078</code>开始:</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="mi">03</span> <span class="mi">04</span>  <span class="cm">/* 倒序索引长度列表 */</span>
<span class="mi">00</span> <span class="mi">00</span> <span class="mi">10</span> <span class="mi">00</span> <span class="mi">36</span>
<span class="mi">30</span> <span class="mi">30</span> <span class="mi">35</span> <span class="mi">38</span>  <span class="cm">/* 列1索引数据 */</span>
<span class="mi">41</span> <span class="mi">31</span> <span class="mi">34</span>  <span class="cm">/* 列2索引数据 */</span>
<span class="mi">80</span> <span class="mi">00</span>  <span class="mi">00</span> <span class="mi">01</span>  <span class="cm">/* 主键id */</span>
</code></pre></div></div>

<p>可以看到， 联合索引的物理存储方式与单一索引的最大区别就是索引数据不是分开存储的。 所以， 联合索引要比两个或多个单独的索引占用更少的磁盘空间。</p>

<p>事实上， 联合索引与单列索引在组织形式上没什么区别， 都是一棵B+Tree。 只不过联合索引的键值数量不是1， 而是大于等于2。</p>

<p><img src="https://smartkeyerror.oss-cn-shenzhen.aliyuncs.com/jojo/system-design/mysql/ibd/union-index.png" alt="" /></p>

<p>如上图所示， 联合索引的第1列数据将严格按照B+Tree的字典序进行排序， 第2列数据则在第一列数据有序的基础上进行排序。 可以认为， 联合索引的B+Tree结构就是对一个多维数组进行排序， 以Python为例:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 假设有如下数据</span>
<span class="n">unsorted_list</span> <span class="o">=</span> <span class="p">[(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>  <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)]</span>

<span class="n">res</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">unsorted_list</span><span class="p">)</span>
<span class="c"># Out: [(1, 2), (1, 3), (2, 4), (2, 5), (4, 1), (4, 2)]</span>
</code></pre></div></div>

<p>假设现在有两列数据a, b组合成为了联合索引， 那么当a列相同时， b列数据一定是有序存放的， 也就是说当执行:</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">SELECT</span> <span class="o">*</span> <span class="k">FROM</span> <span class="k">table</span> <span class="k">WHERE</span> <span class="n">a</span> <span class="o">=</span> <span class="n">XX</span> <span class="k">AND</span> <span class="n">b</span> <span class="o">=</span> <span class="n">XX</span><span class="p">;</span>
</code></pre></div></div>

<p>其效率要高于a, b两个单独的索引列查询， 原因就在于其索引数据保存在同一棵B+Tree中， 使用更少的逻辑I/O就能将数据取出。</p>

<p>在单独查询列a时， 依然可以使用联合索引进行查询， 但是在单独查询b列时， 则不可以使用联合索引。 因为b列数据并不是有序存放的。</p>

<p>如上例所示， b列的数据为<code class="highlighter-rouge">[2, 3, 2, 4, 1, 2]</code>， 完全无序， 故使用:</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">SELECT</span> <span class="o">*</span> <span class="k">FROM</span> <span class="k">table</span> <span class="k">WHERE</span> <span class="n">b</span> <span class="o">=</span> <span class="n">XX</span><span class="p">;</span>
</code></pre></div></div>

<p>进行查询时将无法使用联合索引。 联合索引除了能加速查询以外， 还有另外一个好处， 就是加速<code class="highlighter-rouge">ORDER BY</code>的查询。</p>

<p>这也很好理解， 因为在建立了联合索引以后， 第2列数据， 甚至是第n列数据， 将会有序的组成B+Tree， 如此一来就省去了排序的的时间。</p>

<p>假设现在有4列数据a, b, c, d组成的联合索引(a, b, c, d)， 那么B+Tree的结构为a有序排列， b在a相同的情况下有序排列， c在b相同的情况下有序排列， d在c相同的情况下有序排列。 在查询时， 只要查询条件包含a字段， 均可以使用索引进行查询。</p>

<h4 id="2-覆盖索引cover-index">2. 覆盖索引(Cover Index)</h4>
<p>现在我们已经知道了InnoDB的物理存储方式是一个聚集索引+多个辅助索引组成， 辅助索引包含单列索引以及上面提到的联合索引。 在使用索引进行数据查询时， 首先在辅助索引树中找到该条数据对应的主键id(Row ID)， 而后根据主键id在聚集索引树中进行查询， 粗略的认为就是2次逻辑I/O。</p>

<p>覆盖索引的本质就是不使用聚集索引， 只使用辅助索引就能够将所需要的数据查询出来， 最典型的例子就是<code class="highlighter-rouge">count(*)</code>。</p>

<p>当某张表内存在二级索引时， <code class="highlighter-rouge">count(*)</code>将直接统计二级索引的数量并返回。 由于二级索引的B+Tree要比聚集索引更加的矮胖， 每页能够容纳更多的索引数据行， 所以其效率要高于扫描聚集索引。</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">count_test</span> <span class="p">(</span>
	<span class="n">id</span> <span class="n">int</span><span class="p">(</span><span class="mi">11</span><span class="p">)</span> <span class="k">NOT</span> <span class="k">NULL</span> <span class="n">AUTO_INCREMENT</span><span class="p">,</span>
	<span class="n">user_id</span> <span class="n">varchar</span><span class="p">(</span><span class="mi">8</span><span class="p">)</span> <span class="k">NOT</span> <span class="k">NULL</span><span class="p">,</span>
	<span class="k">PRIMARY</span> <span class="k">KEY</span> <span class="p">(</span><span class="n">id</span><span class="p">),</span>
	<span class="k">KEY</span> <span class="n">ix_user_id</span> <span class="p">(</span><span class="n">user_id</span><span class="p">)</span>
<span class="p">)</span> <span class="n">ENGINE</span><span class="o">=</span><span class="n">InnoDB</span> <span class="k">DEFAULT</span> <span class="n">CHARSET</span><span class="o">=</span><span class="n">LATIN1</span><span class="p">;</span>
</code></pre></div></div>

<p><img src="https://smartkeyerror.oss-cn-shenzhen.aliyuncs.com/jojo/system-design/mysql/ibd/count-with-cover-index.png" alt="" /></p>

<p>如果表内有多个二级索引， 则<code class="highlighter-rouge">count(*)</code>将会选择长度最短的二级索引。 索引长度越短， 每页就能够容纳更多的数据， 就会有更少的逻辑I/O， 因此效率也就越高。</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">ALTER</span> <span class="k">TABLE</span> <span class="n">count_test</span> <span class="k">ADD</span> <span class="n">order_id</span> <span class="n">varchar</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span> <span class="k">NOT</span> <span class="k">NULL</span><span class="p">;</span>
<span class="k">ALTER</span> <span class="k">TABLE</span> <span class="n">count_test</span> <span class="k">ADD</span> <span class="k">KEY</span> <span class="p">(</span><span class="n">order_id</span><span class="p">);</span>
</code></pre></div></div>

<p><img src="https://smartkeyerror.oss-cn-shenzhen.aliyuncs.com/jojo/system-design/mysql/ibd/count-with-shorter-cover-index.png" alt="" /></p>

<p>覆盖索引严格意义上来讲是MySQL的查询优化器所做的优化， 并不是物理上存在的索引。 但是， 借助于覆盖索引的特点， 我们可以有目的的对某些查询进行优化。</p>

<h4 id="3-小结">3. 小结</h4>
<p>联合索引是优化多字段查询以及需要对某个字段进行排序的一种手段， 而覆盖索引则是MySQL查询优化器的一种优化策略， 并不能称为真正意义上的索引。</p>

	  ]]></description>
	</item>

	<item>
	  <title>MySQL物理存储方式</title>
	  <link>//MySQL-physical-structure</link>
	  <author></author>
	  <pubDate>2019-08-15T21:39:25+00:00</pubDate>
	  <guid>//MySQL-physical-structure</guid>
	  <description><![CDATA[
	     <p>MySQL是基于磁盘进行数据存储的关系型数据库， 所有的数据、索引等数据均以磁盘文件的方式存储， 在有需要时载入内存读取。 为了加快数据查询的效率， 通常会在一些字段上添加索引， 但是许多文档都会告诉我们， 不要添加太多的索引， 索引不要太长， 使用数字或者空字符串来代替NULL值， 为什么会有这些建议? 这些建议又是否正确?  答案都能够从MySQL数据的物理存储方式中找到。</p>

<!---more--->

<h4 id="1-innodb文件格式">1. InnoDB文件格式</h4>
<p>由于InnoDB是MySQL使用最为广泛的存储引擎， 所以本篇博文基于InnoDB存储引擎来讨论其数据存储方式。</p>

<p>当我们创建一个table时， InnoDB会创建三个文件。 一个是表结构定义文件， 另一个为数据实际存储文件， 并且所有的索引也将存放在这个文件中。 最后一个文件保存该table所制定的字符集。</p>

<p><img src="https://smartkeyerror.oss-cn-shenzhen.aliyuncs.com/jojo/system-design/mysql/ibd/innodb-table-structure.png" alt="" /></p>

<h4 id="2-innodb行记录格式">2. InnoDB行记录格式</h4>
<p>当我们使用SQL查询一条或者是多条数据时， 数据将会以一行一行的方式返回， 而实际上数据在文件中也的确是使用行记录的方式进行存储的。</p>

<p>不同的InnoDB引擎版本可能有着不同的行记录格式来存放数据， 可以说， 行记录格式的变更将会直接影响到InnoDB的查询以及DML效率。 在MySQL 5.7版本中， 如果对某个table执行:</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">SHOW</span> <span class="k">TABLE</span> <span class="n">STATUS</span> <span class="k">LIKE</span> <span class="nv">"table_name"</span> <span class="err">\</span><span class="k">G</span><span class="p">;</span>
</code></pre></div></div>

<p>将会得到该table的一系列信息， 在这里， 我们只需要知道<code class="highlighter-rouge">Row_format</code>的值即可， 5.7将会返回<code class="highlighter-rouge">Dynamic</code>。</p>

<p>在官网上给出了不同格式的行记录格式之间的差别， 详细内容见官方文档:</p>

<blockquote>
  <p>https://dev.mysql.com/doc/refman/5.7/en/innodb-row-format.html</p>
</blockquote>

<p>在这里我们只需要知道<code class="highlighter-rouge">Dynamic</code>行记录格式在存储可变字符(Varchar)时， 与<code class="highlighter-rouge">Compact</code>行记录格式有着同样的表现即可。</p>

<p><img src="https://smartkeyerror.oss-cn-shenzhen.aliyuncs.com/jojo/system-design/mysql/ibd/Compact-row-format.png" alt="" /></p>

<p>Compact行记录格式将以上图的方式保存在文件中， 需要注意的是， 如果一个table中没有任何的varchar类型， 那么变长字段长度列表将为空。</p>

<p>Compact行记录格式的首部是一个非NULL变长字段长度列表， 并且是按照列的顺序逆序放置的， 其长度表现为:</p>
<ul>
  <li>若列的长度小于255字节， 用1字节表示</li>
  <li>若列的长度大于255字节， 用2字节表示</li>
</ul>

<p>变长字段的长度最大不会超过2字节， 这是因为MySQL中VARCAHR类型的最大长度限制为65535。 变长字段之后的第二个部分为NULL标识位， 该位指示了该行数据中是否存在NULL值， 有则用1表示， 本质上是一个bitmap。</p>

<p>下面用一个实际的例子来具体分析Compact行记录格式的实际存储。</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">-- 创建database</span>
<span class="k">CREATE</span> <span class="k">SCHEMA</span> <span class="nv">`coco`</span> <span class="k">DEFAULT</span> <span class="n">CHARACTER</span> <span class="k">SET</span> <span class="n">latin1</span> <span class="p">;</span>

<span class="c1">-- 创建table</span>
<span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">one</span> <span class="p">(</span>
    <span class="n">id</span> <span class="n">INT</span> <span class="k">NOT</span> <span class="k">NULL</span> <span class="n">AUTO_INCREMENT</span><span class="p">,</span>
    <span class="n">name</span> <span class="n">VARCHAR</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span>
    <span class="n">nickname</span> <span class="n">VARCHAR</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span>
    <span class="k">PRIMARY</span> <span class="k">KEY</span> <span class="p">(</span><span class="n">id</span><span class="p">),</span>
    <span class="k">KEY</span> <span class="p">(</span><span class="n">nickname</span><span class="p">)</span>
<span class="p">)</span> <span class="n">ENGINE</span><span class="o">=</span><span class="n">InnoDB</span> <span class="n">CHARSET</span><span class="o">=</span><span class="n">LATIN1</span><span class="p">;</span>

<span class="c1">-- 插入代表性数据</span>
<span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">one</span> <span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">nickname</span><span class="p">)</span> <span class="k">VALUES</span> <span class="p">(</span><span class="nv">"a"</span><span class="p">,</span> <span class="nv">"AAA"</span><span class="p">);</span>
<span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">one</span> <span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">nickname</span><span class="p">)</span> <span class="k">VALUES</span> <span class="p">(</span><span class="nv">"b"</span><span class="p">,</span> <span class="nv">"BBB"</span><span class="p">);</span>
<span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">one</span> <span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">nickname</span><span class="p">)</span> <span class="k">VALUES</span> <span class="p">(</span><span class="nv">"c"</span><span class="p">,</span> <span class="k">NULL</span><span class="p">);</span>
<span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">one</span> <span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">nickname</span><span class="p">)</span> <span class="k">VALUES</span> <span class="p">(</span><span class="nv">"d"</span><span class="p">,</span> <span class="nv">"DDD"</span><span class="p">);</span>
<span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">one</span> <span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">nickname</span><span class="p">)</span> <span class="k">VALUES</span> <span class="p">(</span><span class="nv">"e"</span><span class="p">,</span> <span class="nv">""</span><span class="p">);</span>
<span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">one</span> <span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">nickname</span><span class="p">)</span> <span class="k">VALUES</span> <span class="p">(</span><span class="nv">"f"</span><span class="p">,</span> <span class="nv">"FFF"</span><span class="p">);</span>
</code></pre></div></div>

<p>而后在<code class="highlighter-rouge">/var/lib/mysql/coco</code>中即可找到该表的<code class="highlighter-rouge">.ibd</code>文件了， 使用<code class="highlighter-rouge">hexdump -C one.ibd</code>对其进行16进制的数据解析并查看。 由于数据太长， 所以仅截取部分数据:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0000c070  73 75 70 72 65 6d 75 6d  03 01 00 00 00 10 00 1d  |supremum........|
0000c080  80 00 00 01 00 00 00 08  d1 29 bd 00 00 01 35 01  |.........<span class="o">)</span>....5.|
0000c090  10 61 41 41 41 03 01 00  00 00 18 00 1c 80 00 00  |.aAAA...........|
0000c0a0  02 00 00 00 08 d1 29 bd  00 00 01 35 01 1d 62 42  |......<span class="o">)</span>....5..bB|
0000c0b0  42 42 01 02 00 00 20 00  1a 80 00 00 03 00 00 00  |BB.... .........|
0000c0c0  08 d1 29 bd 00 00 01 35  01 2a 63 03 01 00 00 00  |..<span class="o">)</span>....5.<span class="k">*</span>c.....|
0000c0d0  28 00 1d 80 00 00 04 00  00 00 08 d1 29 bd 00 00  |<span class="o">(</span>...........<span class="o">)</span>...|
0000c0e0  01 35 01 37 64 44 44 44  00 01 00 00 00 30 00 1a  |.5.7dDDD.....0..|
0000c0f0  80 00 00 05 00 00 00 08  d1 29 bd 00 00 01 35 01  |.........<span class="o">)</span>....5.|
0000c100  44 65 03 01 00 00 00 38  ff 66 80 00 00 06 00 00  |De.....8.f......|
0000c110  00 08 d1 29 bd 00 00 01  35 01 51 66 46 46 46 00  |...<span class="o">)</span>....5.QfFFF.|
</code></pre></div></div>

<p>实际存储数据从<code class="highlighter-rouge">0000c078</code>开始， 使用Compact行记录格式对其进行整理:</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="mi">03</span> <span class="mi">01</span> <span class="cm">/* 变长字段长度列表, 逆序, 第一行varchar数据为('a', 'AAA') */</span>
<span class="mi">00</span> <span class="cm">/* NULL标识位, 该值表示该行未有NULL值的列 */</span>
<span class="mi">00</span> <span class="mi">00</span> <span class="mi">10</span> <span class="mi">00</span> <span class="mi">1</span><span class="n">d</span> <span class="cm">/* 记录头(Record Header)信息, 固定长度为5字节 */</span>
<span class="mi">80</span> <span class="mi">00</span> <span class="mi">00</span> <span class="mi">01</span> <span class="cm">/* Row ID, 这里即为该行数据的主键值(paimary key)，长度为4 */</span>
<span class="mi">00</span> <span class="mi">00</span> <span class="mi">00</span> <span class="mi">08</span> <span class="n">d1</span> <span class="mi">29</span> <span class="cm">/* Transaction ID, 即事务ID, 默认为6字节 */</span>
<span class="n">bd</span> <span class="mi">00</span> <span class="mi">00</span> <span class="mi">01</span> <span class="mi">35</span> <span class="mi">01</span> <span class="mi">10</span> <span class="cm">/* 回滚指针, 默认为7字节 */</span>
<span class="mi">61</span> <span class="cm">/* 列1数据'a' */</span>
<span class="mi">41</span> <span class="mi">41</span> <span class="mi">41</span> <span class="cm">/* 列2数据'AAA' */</span>
</code></pre></div></div>

<p>第2行数据与第1行数据大同小异， 值得关注的是包含有NULL值以及空值的行， 即第3行和第5行， 首先来看第3行数据:</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="mi">01</span> <span class="cm">/* 由于该行中只有一列数据类型为varchar，并且非NULL, 所以列表长度为1 */</span>
<span class="mi">02</span> <span class="cm">/* 02转换为2进制结果为10, 表示第二列数据为NULL(注意是逆序) */</span>
<span class="mi">00</span> <span class="mi">00</span> <span class="mi">20</span> <span class="mi">00</span> <span class="mi">1</span><span class="n">a</span> <span class="cm">/* 记录头(Record Header)信息, 固定长度为5字节 */</span>
<span class="mi">80</span> <span class="mi">00</span> <span class="mi">00</span> <span class="mi">03</span> <span class="cm">/* 第3行数据的主键id */</span>
<span class="mi">00</span> <span class="mi">00</span> <span class="mi">00</span> <span class="mi">08</span> <span class="n">d1</span> <span class="mi">29</span>  <span class="cm">/* Transaction ID, 即事务ID, 默认为6字节 */</span>
<span class="n">bd</span> <span class="mi">00</span> <span class="mi">00</span> <span class="mi">01</span> <span class="mi">35</span>  <span class="mi">01</span> <span class="mi">2</span><span class="n">a</span> <span class="cm">/* 回滚指针, 默认为7字节 */</span>
<span class="mi">63</span> <span class="cm">/* 列1数据'c' */</span>
</code></pre></div></div>

<p>可以非常明显的看到， NULL值并没有在文件中进行存储， 而是仅使用NULL标识位来标记某一列是否为NULL。 所以说， NULL值不会占据任何的物理存储空间， 相反， varchar类型的NULL值还会少占用变长字段长度列表空间。</p>

<p>再来看空字符串所在的第5行数据:</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="mi">00</span> <span class="mi">01</span>  <span class="cm">/* 表示第2列的varchar长度为0 */</span>
<span class="mi">00</span>  <span class="cm">/* 该行没有NULL值的列 */</span>
<span class="mi">00</span> <span class="mi">00</span> <span class="mi">30</span> <span class="mi">00</span> <span class="mi">1</span><span class="n">a</span>  <span class="cm">/* 记录头(Record Header)信息, 固定长度为5字节 */</span>
<span class="mi">80</span> <span class="mi">00</span> <span class="mi">00</span> <span class="mi">05</span>  <span class="cm">/* 第5行数据的主键id */</span>
<span class="mi">00</span> <span class="mi">00</span> <span class="mi">00</span> <span class="mi">08</span> <span class="n">d1</span> <span class="mi">29</span>  <span class="cm">/* Transaction ID, 即事务ID, 默认为6字节 */</span>
<span class="n">bd</span> <span class="mi">00</span> <span class="mi">00</span> <span class="mi">01</span> <span class="mi">35</span> <span class="mi">01</span> <span class="mi">44</span>   <span class="cm">/* 回滚指针, 默认为7字节 */</span>
<span class="mi">65</span>  <span class="cm">/* 列1数据'e' */</span>
</code></pre></div></div>

<p>可以看到， 空字符串和NULL值一样， 也不占用任何的磁盘存储空间。 只不过与NULL值不同的是， 在首部的变长字符长度列表中仍然占据存储空间， 但是值为0。</p>

<h4 id="3-数据的聚集索引组织方式">3. 数据的聚集索引组织方式</h4>
<p>有些人将聚集索引(Cluster Index)理解成为主键， 或者是主键索引， 这是不准确的。 聚集索引并不是一种索引结构， 而是一种数据的组织方式， 用唯一且不为空的主键来对所有的数据进行组织。 主键， 是最为常见的聚集索引对外表现的形式。</p>

<p>聚集索引最大的特点就在于数据在逻辑上是一定是连续的， 但是在物理是并不一定连续。 比如我们常见的自增主键， 当我们对查询语句不做任何处理时， 默认就是按照主键的递增顺序返回的。</p>

<p>而辅助索引， 或者是二级索引， 是由程序员人为的在某些列上所添加的索引。 辅助索引所代表的数据在逻辑上不一定连续， 物理存储上也不一定连续。</p>

<p>MySQL使用B+Tree来组织数据和索引(关于B+Tree的详细内容， 可见下方传送门)， 在非叶子节点中保存着索引和指针， 在叶子节点保存着数据。 情况又分两种:</p>
<ul>
  <li>聚集索引的叶子节点保存着实际的数据，即一行完整的数据</li>
  <li>辅助索引的叶子节点保存着该行数据的主键ID</li>
</ul>

<p><a href="https://smartkeyerror.com/%E9%82%A3%E4%BA%9B%E6%9C%89%E8%B6%A3%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95-04-B-Tree%E4%B8%8EB-Tree.html">那些有趣的数据结构与算法(04)–B-Tree与B+Tree</a></p>

<p>也就是说， 假设聚集索引和辅助索引的B+Tree树高均为3的话， 使用主键查询需要3次逻辑I/O。 而使用辅助索引则需要6次逻辑I/O才能找到该行数据。</p>

<p><img src="https://smartkeyerror.oss-cn-shenzhen.aliyuncs.com/jojo/system-design/mysql/ibd/Cluster-Index.png" alt="" /></p>

<p>还记得在上面的Compact行记录格式中的行记录头， 也就是Record Header信息吗?  Record Header的最后两个字节表示下一行数据的偏移量， 其实这个就是B+Tree中的指针。 例如第一行的起始位置为c078， Record Header最后两个字节为001d， 加起来等于c095， 刚好是第二行的起始位置。</p>

<p>在上面的例子中， 我们创建了这样的一张表:</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">one</span> <span class="p">(</span>
    <span class="n">id</span> <span class="n">INT</span> <span class="k">NOT</span> <span class="k">NULL</span> <span class="n">AUTO_INCREMENT</span><span class="p">,</span>
    <span class="n">name</span> <span class="n">VARCHAR</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span>
    <span class="n">nickname</span> <span class="n">VARCHAR</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span>
    <span class="k">PRIMARY</span> <span class="k">KEY</span> <span class="p">(</span><span class="n">id</span><span class="p">),</span>
    <span class="k">KEY</span> <span class="p">(</span><span class="n">nickname</span><span class="p">)</span>
<span class="p">)</span> <span class="n">ENGINE</span><span class="o">=</span><span class="n">InnoDB</span> <span class="n">CHARSET</span><span class="o">=</span><span class="n">LATIN1</span><span class="p">;</span>
</code></pre></div></div>

<p>其中<code class="highlighter-rouge">nickname</code>字段被我们添加了辅助索引， 同样地， 可以使用<code class="highlighter-rouge">.ibd</code>文件来具体对其结构进行分析。 使用<code class="highlighter-rouge">hexdump -C one.ibd</code>解析文件并找到辅助索引开始的地方:</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="mi">00010060</span>  <span class="mi">02</span> <span class="mi">00</span> <span class="mi">37</span> <span class="mi">69</span> <span class="mi">6</span><span class="n">e</span> <span class="mi">66</span> <span class="mi">69</span> <span class="mi">6</span><span class="n">d</span>  <span class="mi">75</span> <span class="mi">6</span><span class="n">d</span> <span class="mi">00</span> <span class="mi">07</span> <span class="mi">00</span> <span class="mi">0</span><span class="n">b</span> <span class="mi">00</span> <span class="mi">00</span>  <span class="o">|</span><span class="p">..</span><span class="mi">7</span><span class="n">infimum</span><span class="p">......</span><span class="o">|</span>
<span class="mi">00010070</span>  <span class="mi">73</span> <span class="mi">75</span> <span class="mi">70</span> <span class="mi">72</span> <span class="mi">65</span> <span class="mi">6</span><span class="n">d</span> <span class="mi">75</span> <span class="mi">6</span><span class="n">d</span>  <span class="mi">03</span> <span class="mi">00</span> <span class="mi">00</span> <span class="mi">00</span> <span class="mi">10</span> <span class="mi">00</span> <span class="mi">0</span><span class="n">e</span> <span class="mi">41</span>  <span class="o">|</span><span class="n">supremum</span><span class="p">.......</span><span class="n">A</span><span class="o">|</span>
<span class="mi">00010080</span>  <span class="mi">41</span> <span class="mi">41</span> <span class="mi">80</span> <span class="mi">00</span> <span class="mi">00</span> <span class="mi">01</span> <span class="mi">03</span> <span class="mi">00</span>  <span class="mi">00</span> <span class="mi">00</span> <span class="mi">18</span> <span class="mi">00</span> <span class="mi">18</span> <span class="mi">42</span> <span class="mi">42</span> <span class="mi">42</span>  <span class="o">|</span><span class="n">AA</span><span class="p">...........</span><span class="n">BBB</span><span class="o">|</span>
<span class="mi">00010090</span>  <span class="mi">80</span> <span class="mi">00</span> <span class="mi">00</span> <span class="mi">02</span> <span class="mi">01</span> <span class="mi">00</span> <span class="mi">00</span> <span class="mi">20</span>  <span class="mi">00</span> <span class="mi">19</span> <span class="mi">80</span> <span class="mi">00</span> <span class="mi">00</span> <span class="mi">03</span> <span class="mi">03</span> <span class="mi">00</span>  <span class="o">|</span><span class="p">.......</span> <span class="p">........</span><span class="o">|</span>
<span class="mi">000100</span><span class="n">a0</span>  <span class="mi">00</span> <span class="mi">00</span> <span class="mi">28</span> <span class="mi">00</span> <span class="mi">19</span> <span class="mi">44</span> <span class="mi">44</span> <span class="mi">44</span>  <span class="mi">80</span> <span class="mi">00</span> <span class="mi">00</span> <span class="mi">04</span> <span class="mi">00</span> <span class="mi">00</span> <span class="mi">00</span> <span class="mi">00</span>  <span class="o">|</span><span class="p">..(..</span><span class="n">DDD</span><span class="p">........</span><span class="o">|</span>
<span class="mi">000100</span><span class="n">b0</span>  <span class="mi">30</span> <span class="n">ff</span> <span class="n">cc</span> <span class="mi">80</span> <span class="mi">00</span> <span class="mi">00</span> <span class="mi">05</span> <span class="mi">03</span>  <span class="mi">00</span> <span class="mi">00</span> <span class="mi">00</span> <span class="mi">38</span> <span class="n">ff</span> <span class="n">b2</span> <span class="mi">46</span> <span class="mi">46</span>  <span class="o">|</span><span class="mi">0</span><span class="p">..........</span><span class="mi">8</span><span class="p">..</span><span class="n">FF</span><span class="o">|</span>
<span class="mi">000100</span><span class="n">c0</span>  <span class="mi">46</span> <span class="mi">80</span> <span class="mi">00</span> <span class="mi">00</span> <span class="mi">06</span> <span class="mi">00</span> <span class="mi">00</span> <span class="mi">00</span>  <span class="mi">00</span> <span class="mi">00</span> <span class="mi">00</span> <span class="mi">00</span> <span class="mi">00</span> <span class="mi">00</span> <span class="mi">00</span> <span class="mi">00</span>  <span class="o">|</span><span class="n">F</span><span class="p">...............</span><span class="o">|</span>
<span class="mi">000100</span><span class="n">d0</span>  <span class="mi">00</span> <span class="mi">00</span> <span class="mi">00</span> <span class="mi">00</span> <span class="mi">00</span> <span class="mi">00</span> <span class="mi">00</span> <span class="mi">00</span>  <span class="mi">00</span> <span class="mi">00</span> <span class="mi">00</span> <span class="mi">00</span> <span class="mi">00</span> <span class="mi">00</span> <span class="mi">00</span> <span class="mi">00</span>  <span class="o">|</span><span class="p">................</span><span class="o">|</span>
</code></pre></div></div>

<p>索引数据从00010078的位置开始， 逐行进行分析即可:</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="mi">03</span>  <span class="cm">/* 当前索引字段的长度 */</span>
<span class="mi">00</span> <span class="mi">00</span> <span class="mi">00</span> <span class="mi">10</span> <span class="mi">00</span> <span class="mi">0</span><span class="n">e</span> <span class="cm">/* 不知道是啥 */</span>
<span class="mi">41</span> <span class="mi">41</span> <span class="mi">41</span>   <span class="cm">/* 索引值 */</span>
<span class="mi">80</span> <span class="mi">00</span> <span class="mi">00</span> <span class="mi">01</span>  <span class="cm">/* 指向的主键id */</span>
</code></pre></div></div>

<p>第2行与第1行基本类似， 现在来看看比较特殊的第3行与第5行。 第3行索引数据内容:</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="mi">01</span>
<span class="mi">00</span> <span class="mi">00</span> <span class="mi">20</span> <span class="mi">00</span> <span class="mi">19</span>
<span class="mi">80</span> <span class="mi">00</span> <span class="mi">00</span> <span class="mi">03</span>  <span class="cm">/* 指向的主键id */</span>
</code></pre></div></div>

<p>当索引的内容为NULL值时， 辅助索引的文件格式也变得奇怪了起来， 和第一行完全不一样， 再来看看第5行:</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="mi">00</span>  <span class="cm">/* 当前索引字段的长度 */</span>
<span class="mi">00</span> <span class="mi">00</span> <span class="mi">00</span> <span class="mi">30</span> <span class="n">ff</span> <span class="n">cc</span>
<span class="mi">80</span> <span class="mi">00</span> <span class="mi">00</span> <span class="mi">05</span>  <span class="cm">/* 指向的主键id */</span>
</code></pre></div></div>

<p>和正常索引内容基本类似， 空字符串仍然没有表示， 仅使用了00表示该字段长度为0。</p>

<h4 id="4-辅助索引叶子节点存储方式">4. 辅助索引叶子节点存储方式</h4>
<p>在MySQL中， 数据管理的最小单元为页(page)， 而并非一行一行的数据。 数据保存在页中， 当我们使用主键查找一行数据时， 其实MySQL并不能直接返回这一行数据， 而是将该行所在的页载入内存， 然后在内存页中进行查找。</p>

<p>通常情况下页大小为16K， 在某些情况下可能会对页进行压缩， 使得页大小为8K或者是4K。 由于B+Tree的特点， 使得每一页内最少为2行数据， 再少就将退化成链表， 显然出于效率的考量不会让此种情况出现。 故而一行数据大小至多为16K， 通过该特性， 就可以研究二级索引的叶子节点是什么样子的了。</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">two</span> <span class="p">(</span>
    <span class="n">id</span> <span class="n">INT</span> <span class="k">NOT</span> <span class="k">NULL</span> <span class="n">AUTO_INCREMENT</span><span class="p">,</span>
    <span class="n">name</span> <span class="n">VARCHAR</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span>
    <span class="n">nickname</span> <span class="n">VARCHAR</span><span class="p">(</span><span class="mi">8000</span><span class="p">),</span>
    <span class="k">PRIMARY</span> <span class="k">KEY</span> <span class="p">(</span><span class="n">id</span><span class="p">),</span>
    <span class="k">KEY</span> <span class="p">(</span><span class="n">nickname</span><span class="p">(</span><span class="mi">2000</span><span class="p">))</span>
<span class="p">)</span> <span class="n">ENGINE</span><span class="o">=</span><span class="n">InnoDB</span> <span class="n">CHARSET</span><span class="o">=</span><span class="n">LATIN1</span><span class="p">;</span>

<span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">two</span> <span class="k">SELECT</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">'a'</span><span class="p">,</span> <span class="n">REPEAT</span><span class="p">(</span><span class="s1">'A'</span><span class="p">,</span> <span class="mi">8000</span><span class="p">);</span>
<span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">two</span> <span class="k">SELECT</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">'b'</span><span class="p">,</span> <span class="k">NULL</span><span class="p">;</span>
<span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">two</span> <span class="k">SELECT</span> <span class="mi">3</span><span class="p">,</span> <span class="s1">'c'</span><span class="p">,</span> <span class="n">REPEAT</span><span class="p">(</span><span class="s1">'C'</span><span class="p">,</span> <span class="mi">8000</span><span class="p">);</span>
<span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">two</span> <span class="k">SELECT</span> <span class="mi">4</span><span class="p">,</span> <span class="s1">'d'</span><span class="p">,</span> <span class="k">NULL</span><span class="p">;</span>
<span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">two</span> <span class="k">SELECT</span> <span class="mi">5</span><span class="p">,</span> <span class="s1">'e'</span><span class="p">,</span> <span class="n">REPEAT</span><span class="p">(</span><span class="s1">'E'</span><span class="p">,</span> <span class="mi">8000</span><span class="p">);</span>
<span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">two</span> <span class="k">SELECT</span> <span class="mi">6</span><span class="p">,</span> <span class="s1">'f'</span><span class="p">,</span> <span class="n">REPEAT</span><span class="p">(</span><span class="s1">'F'</span><span class="p">,</span> <span class="mi">8000</span><span class="p">);</span>
<span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">two</span> <span class="k">SELECT</span> <span class="mi">7</span><span class="p">,</span> <span class="s1">'g'</span><span class="p">,</span> <span class="k">NULL</span><span class="p">;</span>
<span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">two</span> <span class="k">SELECT</span> <span class="mi">8</span><span class="p">,</span> <span class="s1">'h'</span><span class="p">,</span> <span class="n">REPEAT</span><span class="p">(</span><span class="s1">'H'</span><span class="p">,</span> <span class="mi">8000</span><span class="p">);</span>
<span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">two</span> <span class="k">SELECT</span> <span class="mi">9</span><span class="p">,</span> <span class="s1">'i'</span><span class="p">,</span> <span class="n">REPEAT</span><span class="p">(</span><span class="s1">'G'</span><span class="p">,</span> <span class="mi">8000</span><span class="p">);</span>
<span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">two</span> <span class="k">SELECT</span> <span class="mi">10</span><span class="p">,</span> <span class="s1">'i'</span><span class="p">,</span> <span class="nv">""</span><span class="p">;</span>
</code></pre></div></div>

<p>由于索引长度的限制， 这里仅取nickname的前2000个字符进行索引， 并插入一些具有代表性的数据。 同样使用<code class="highlighter-rouge">hexdump -C two.ibd</code>对索引结构进行分析:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>00010070  73 75 70 72 65 6d 75 6d  d0 87 00 05 00 10 07 e6  |supremum........|
00010080  41 41 41 41 41 41 41 41  41 41 41 41 41 41 41 41  |AAAAAAAAAAAAAAAA|
<span class="k">*</span>
00010850  80 00 00 01 01 00 00 18  07 e6 80 00 00 02 d0 87  |................|
00010860  00 00 00 20 07 e6 43 43  43 43 43 43 43 43 43 43  |... ..CCCCCCCCCC|
00010870  43 43 43 43 43 43 43 43  43 43 43 43 43 43 43 43  |CCCCCCCCCCCCCCCC|
<span class="k">*</span>
00011030  43 43 43 43 43 43 80 00  00 03 01 00 00 28 0f c2  |CCCCCC.......<span class="o">(</span>..|
00011040  80 00 00 04 d0 87 00 00  00 30 07 dc 45 45 45 45  |.........0..EEEE|
00011050  45 45 45 45 45 45 45 45  45 45 45 45 45 45 45 45  |EEEEEEEEEEEEEEEE|
<span class="k">*</span>
00011810  45 45 45 45 45 45 45 45  45 45 45 45 80 00 00 05  |EEEEEEEEEEEE....|
00011820  d0 87 00 00 00 38 0f c2  46 46 46 46 46 46 46 46  |.....8..FFFFFFFF|
00011830  46 46 46 46 46 46 46 46  46 46 46 46 46 46 46 46  |FFFFFFFFFFFFFFFF|
<span class="k">*</span>
00011ff0  46 46 46 46 46 46 46 46  80 00 00 06 01 00 00 40  |FFFFFFFF.......@|
00012000  0f c3 80 00 00 07 d0 87  00 00 00 48 e0 62 48 48  |...........H.bHH|
00012010  48 48 48 48 48 48 48 48  48 48 48 48 48 48 48 48  |HHHHHHHHHHHHHHHH|
<span class="k">*</span>
000127d0  48 48 48 48 48 48 48 48  48 48 48 48 48 48 80 00  |HHHHHHHHHHHHHH..|
000127e0  00 08 d0 87 00 00 00 50  f8 24 47 47 47 47 47 47  |.......P.<span class="nv">$GGGGGG</span>|
000127f0  47 47 47 47 47 47 47 47  47 47 47 47 47 47 47 47  |GGGGGGGGGGGGGGGG|
<span class="k">*</span>
00012fb0  47 47 47 47 47 47 47 47  47 47 80 00 00 09 00 00  |GGGGGGGGGG......|
00012fc0  00 00 58 d0 bb 80 00 00  0a 00 00 00 00 00 00 00  |..X.............|
00012fd0  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|
</code></pre></div></div>

<p>从上表中可以看到， 索引数据起始点为00010078， 逐行进行分析可以发现， NULL值和空值的表现形式与上一小节分析的基本相同。</p>

<p>NULL值行:</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="mi">01</span>
<span class="mi">00</span> <span class="mi">00</span> <span class="mi">18</span> <span class="mi">07</span> <span class="n">e6</span>
<span class="mi">80</span> <span class="mi">00</span> <span class="mi">00</span> <span class="mi">02</span>  <span class="cm">/* 主键id */</span>

<span class="mi">01</span>
<span class="mi">00</span> <span class="mi">00</span> <span class="mi">28</span> <span class="mi">0</span><span class="n">f</span> <span class="n">c2</span>
<span class="mi">80</span> <span class="mi">00</span> <span class="mi">00</span> <span class="mi">04</span>  <span class="cm">/* 主键id */</span>

<span class="mi">01</span>
<span class="mi">00</span> <span class="mi">00</span> <span class="mi">40</span> <span class="mi">0</span><span class="n">f</span> <span class="n">c3</span>
<span class="mi">80</span> <span class="mi">00</span> <span class="mi">00</span> <span class="mi">07</span>  <span class="cm">/* 主键id */</span>
</code></pre></div></div>

<p>空字符串行:</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="mi">00</span>
<span class="mi">00</span> <span class="mi">00</span> <span class="mi">00</span> <span class="mi">58</span> <span class="n">d0</span> <span class="n">bb</span>
<span class="mi">80</span> <span class="mi">00</span> <span class="mi">00</span> <span class="mi">0</span><span class="n">a</span>  <span class="cm">/* 主键id */</span>
</code></pre></div></div>

<p>所以说， 分析到这里， 我们完全有理由说NULL值要比空值占用更少的物理存储空间， 包含索引存储空间。 但是， 这是在我们所定义表结构时允许字段值为NULL的前提下， 当我们显式的指定IS NOT NULL时， 情况又会不一样。</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">three</span> <span class="p">(</span>
    <span class="n">id</span> <span class="n">INT</span> <span class="k">NOT</span> <span class="k">NULL</span> <span class="n">AUTO_INCREMENT</span><span class="p">,</span>
    <span class="n">name</span> <span class="n">VARCHAR</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span> <span class="k">NOT</span> <span class="k">NULL</span><span class="p">,</span>
    <span class="n">nickname</span> <span class="n">VARCHAR</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span> <span class="k">NOT</span> <span class="k">NULL</span><span class="p">,</span>
    <span class="k">PRIMARY</span> <span class="k">KEY</span> <span class="p">(</span><span class="n">id</span><span class="p">),</span>
    <span class="k">KEY</span> <span class="p">(</span><span class="n">nickname</span><span class="p">)</span>
<span class="p">)</span> <span class="n">ENGINE</span><span class="o">=</span><span class="n">InnoDB</span> <span class="n">CHARSET</span><span class="o">=</span><span class="n">LATIN1</span><span class="p">;</span>

<span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">three</span> <span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">nickname</span><span class="p">)</span> <span class="k">VALUES</span> <span class="p">(</span><span class="nv">"a"</span><span class="p">,</span> <span class="nv">"AAA"</span><span class="p">);</span>
<span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">three</span> <span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">nickname</span><span class="p">)</span> <span class="k">VALUES</span> <span class="p">(</span><span class="nv">"b"</span><span class="p">,</span> <span class="nv">""</span><span class="p">);</span>
<span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">three</span> <span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">nickname</span><span class="p">)</span> <span class="k">VALUES</span> <span class="p">(</span><span class="nv">"c"</span><span class="p">,</span> <span class="nv">"CCC"</span><span class="p">);</span>
<span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">three</span> <span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">nickname</span><span class="p">)</span> <span class="k">VALUES</span> <span class="p">(</span><span class="nv">"d"</span><span class="p">,</span> <span class="nv">"DDD"</span><span class="p">);</span>
<span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">three</span> <span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">nickname</span><span class="p">)</span> <span class="k">VALUES</span> <span class="p">(</span><span class="nv">"e"</span><span class="p">,</span> <span class="nv">"EEE"</span><span class="p">);</span>
<span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">three</span> <span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">nickname</span><span class="p">)</span> <span class="k">VALUES</span> <span class="p">(</span><span class="nv">"f"</span><span class="p">,</span> <span class="nv">""</span><span class="p">);</span>
<span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">three</span> <span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">nickname</span><span class="p">)</span> <span class="k">VALUES</span> <span class="p">(</span><span class="nv">"g"</span><span class="p">,</span> <span class="nv">"GGG"</span><span class="p">);</span>
</code></pre></div></div>

<p><code class="highlighter-rouge">hexdump -C three.ibd</code>可得:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0000c070  73 75 70 72 65 6d 75 6d  03 01 00 00 10 00 1c 80  |supremum........|
0000c080  00 00 01 00 00 00 08 dd  21 ba 00 00 01 2f 01 10  |........!..../..|
0000c090  61 41 41 41 00 01 00 00  18 00 19 80 00 00 02 00  |aAAA............|
0000c0a0  00 00 08 dd 22 bb 00 00  01 31 01 10 62 03 01 00  |....<span class="s2">"....1..b...|
0000c0b0  00 20 00 1c 80 00 00 03  00 00 00 08 dd 25 bd 00  |. ...........%..|
0000c0c0  00 01 35 01 10 63 43 43  43 03 01 00 00 28 00 1c  |..5..cCCC....(..|
0000c0d0  80 00 00 04 00 00 00 08  dd 28 bf 00 00 01 36 01  |.........(....6.|
0000c0e0  10 64 44 44 44 03 01 00  00 30 00 1c 80 00 00 05  |.dDDD....0......|
0000c0f0  00 00 00 08 dd 29 c0 00  00 01 37 01 10 65 45 45  |.....)....7..eEE|
0000c100  45 00 01 00 00 38 00 19  80 00 00 06 00 00 00 08  |E....8..........|
0000c110  dd 2a a1 00 00 01 12 01  10 66 03 01 00 00 40 ff  |.*.......f....@.|
0000c120  4f 80 00 00 07 00 00 00  08 dd 2b a2 00 00 01 15  |O.........+.....|
0000c130  01 10 67 47 47 47 00 00  00 00 00 00 00 00 00 00  |..gGGG..........|
</span></code></pre></div></div>

<p>数据从c078开始， 同样进行逐行分析:</p>

<p>第一行数据:</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="mi">03</span> <span class="mi">01</span>  <span class="cm">/* 逆序可变字符长度列表 */</span>
<span class="mi">00</span> <span class="mi">00</span> <span class="mi">10</span> <span class="mi">00</span> <span class="mi">1</span><span class="k">c</span>  <span class="cm">/* 记录头信息(Record Header), c078+001c=c094 */</span>
<span class="mi">80</span> <span class="mi">00</span> <span class="mi">00</span> <span class="mi">01</span>  <span class="cm">/* 主键id */</span>
<span class="c1">-- Transaction ID + Roll Pointer</span>
<span class="mi">61</span>  <span class="cm">/* 列1数据 */</span>
<span class="mi">41</span> <span class="mi">41</span> <span class="mi">41</span>  <span class="cm">/* 列2数据 */</span>
</code></pre></div></div>

<p>第二行数据</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="mi">00</span> <span class="mi">01</span>  <span class="cm">/* 逆序可变字符长度列表 */</span>
<span class="mi">00</span> <span class="mi">00</span> <span class="mi">18</span> <span class="mi">00</span> <span class="mi">19</span>  <span class="cm">/* 记录头信息(Record Header), c094+0019=c0ad */</span>
<span class="mi">80</span> <span class="mi">00</span> <span class="mi">00</span> <span class="mi">02</span>  <span class="cm">/* 主键id */</span>
<span class="c1">-- Transaction ID + Roll Pointer</span>
<span class="mi">62</span>  <span class="cm">/* 列1数据, 列2数据为空值, 故无记录 */</span>
</code></pre></div></div>

<p>第三行数据:</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="mi">03</span> <span class="mi">01</span>  <span class="cm">/* 逆序可变字符长度列表 */</span>
<span class="mi">00</span> <span class="mi">00</span> <span class="mi">20</span> <span class="mi">00</span> <span class="mi">1</span><span class="k">c</span>  <span class="cm">/* 记录头信息(Record Header), c0ad+001c=c0c9 */</span>
<span class="mi">80</span> <span class="mi">00</span> <span class="mi">00</span> <span class="mi">03</span>  <span class="cm">/* 主键id */</span>
<span class="c1">-- Transaction ID + Roll Pointer</span>
<span class="mi">63</span>  <span class="cm">/* 列1数据 */</span>
<span class="mi">43</span> <span class="mi">43</span> <span class="mi">43</span>  <span class="cm">/* 列2数据 */</span>
</code></pre></div></div>

<p>可以看到， 将<strong>所有</strong>的列设置为NOT NULL之后， 存储内容少了一个NULL标识位， 此时该table的存储效率要高于最初的表结构。</p>

<p>所以说， 如果想要真正的节省表空间存储大小， 需要将<strong>所有</strong>的字段都设置为NOT NULL约束， 否则在存储时仍然需要NULL标识位来标记哪一列数据为非NULL， 即使所有的列都有数据。</p>

<p>最后， NULL真的比空字符串占用更少的空间吗? 答案是不一定。 如果在定义表结构时指定了NOT NULL， 那么数据中就不可能出现NULL值， 也就无从比起。 如果在定义表结构时没有指定NOT NULL， 那么NULL将会比空字符串占用更少的空间。</p>

<h4 id="5-总结">5. 总结</h4>
<p>经过对<code class="highlighter-rouge">.ibd</code>文件的分析， 想必对数据以及索引的组织方式有了一个更加清晰的了解， 并且也能够判断出各种各样优化建议到底是否正确了。</p>

<p>使用数字或者是空串来代替NULL值? 没有必要， 有时还会适得其反， 而且对于添加了二级索引的NULL值， 查询仍然会使用索引。 正确的做法就是在定义表结构的时候就将NULL值扼杀在摇篮里， 如此一来能够节省一部分的磁盘空间以及一定程度上的效率提升。</p>

<p>为什么索引不能太多? 因为每添加一个索引， <code class="highlighter-rouge">.ibd</code>文件中就需要多维护一个B+Tree索引树， 如果某一个table中存在10个索引， 那么就需要维护10棵B+Tree， 写入效率会降低， 并且会浪费磁盘空间。</p>

<p>B+Tree中的指针是用什么实现的? 使用文件偏移量实现， 指向下一行或者是下一个索引的起始位置。</p>

	  ]]></description>
	</item>

	<item>
	  <title>数据变更操作日志设计</title>
	  <link>//change-log-system-design</link>
	  <author></author>
	  <pubDate>2019-08-10T21:39:25+00:00</pubDate>
	  <guid>//change-log-system-design</guid>
	  <description><![CDATA[
	     <p>当系统的某些行为涉及到资金与资产的数据变更时，常常会为其增加操作日志， 便于后续的问题排查。 例如红包的使用明细， 银行转账的详细记录等等。 操作日志记录这个需求看起来很简单， 但是深挖下去， 依然能找到很有趣的东西。</p>

<!---more--->

<h4 id="1-需求">1. 需求</h4>
<p>既然是操作日志， 势必要记录<strong>谁对什么进行了怎样的操作</strong>， 抽象出来的字段就有<code class="highlighter-rouge">operator</code>(操作人)， <code class="highlighter-rouge">action</code>(创建、修改等行为)， <code class="highlighter-rouge">entry</code>(实体, 通常会用实体id来代替)。</p>

<p>MySQL-binlog的日志格式有<code class="highlighter-rouge">FULL</code>和<code class="highlighter-rouge">MINIMAL</code>两种， 前者记录了所有的字段， 后者只记录了更新的部分字段。 那么对于操作日志而言， 同样需要考虑是记录更新前后的所有数据字段， 还是只记录更新的字段。 操作日志的数据当然是越详细越好， 既然都要做这个需求了， 那就一步到位。</p>

<p>所以说， 本篇文章的日志格式即为数据库数据的增量版， 并且在原有数据字段上进行稍许拓展， 进行更加详细的记录。 也可以认为这就是记录了所有的数据版本库， 此时添加一个版本号即可。</p>

<h4 id="2-实现">2. 实现</h4>
<p>理论上来讲实现有两种， 一种是业务层面实现， 一种是使用日志解析工具来解析二进制日志， 但是该实现方式非常依赖具体的存储实现， 像MySQL和Oracle的解析策略是不一样的， 如果使用了MongoDB作为主库存储， 数据文件解析起来就更费劲了。</p>

<p>从项目维护的角度来看， 业务层实现在编码完成之后， 几乎不需要花太多的精力维护。 但是日志解析或者是数据文件解析工具， 却需要花大量的人力和时间来维护(看看<code class="highlighter-rouge">canal</code>)。</p>

<p>从易拓展的角度来看， 业务层的实现只需要稍加抽象， 就可以随意的更换或者添加数据存储源。 而日志分析的实现如果需要更换数据源的话， 迁移的工作量可能相当庞大。</p>

<p>从效率的角度来看， 业务层的实现效率确实会低于日志解析的实现。</p>

<p>综上考虑， 业务层实现是最佳的方式， 方便维护， 方便拓展， 在效率上虽然会对原有系统造成影响， 但是可以通过其它的方式进行补偿。</p>

<h4 id="3-实现细节">3. 实现细节</h4>

<p>在具体的实现之前， 首先来看一下常见Web请求的基本流程， 当然， 这里只针对创建、修改和删除操作:</p>

<p><img src="https://smartkeyerror.oss-cn-shenzhen.aliyuncs.com/jojo/system-design/operation-log/data-stream.png" alt="" /></p>

<p>当对创建请求进行操作日志记录时， 完全可以将经过表单验证以及逻辑处理后的数据直接写入到日志记录库， 并添加一些附属信息， 如操作人， 操作的动作(create)， 来源IP等等。</p>

<p>但是对于更新操作呢? 通常只会进行部分字段的更新， 而后直接使用</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">update</span> <span class="p">...</span> <span class="k">set</span> <span class="n">field</span> <span class="o">=</span> <span class="n">value</span> <span class="k">where</span> <span class="p">...;</span>
</code></pre></div></div>

<p>进行部分字段或者是批量更新。 但是为了记录更新后的完整数据， 那么就需要在更新后再将数据取出， 添加附属信息， 并插入日志记录库。 如此一来相比原来，多了一次查询操作。</p>

<p>如果不使用<code class="highlighter-rouge">update</code>语句， 使用<code class="highlighter-rouge">instance.save</code>方式呢? 即先将数据取出， 而后更新数据， 将更新的数据写回DB并插入操作日志。</p>

<p><img src="https://smartkeyerror.oss-cn-shenzhen.aliyuncs.com/jojo/system-design/operation-log/get-and-update.png" alt="" /></p>

<p>在使用ORM的应用中， 这样的代码其实很常见， 一个最大的问题就是并发时的数据问题， 先更新的语句可能会覆盖掉另外一条后更新的语句， 导致数据混乱。</p>

<p>原因就在于取出数据-更新数据不是一个原子性的操作， 底层的数据库因为并发执行导致多条语句的执行顺序并不受程序控制。 所以我们要么寻找一种能够原子性执行的方式， 要么对数据添加行锁。 首先来看行锁的方式:</p>

<p>使用<code class="highlighter-rouge">select for update</code>对数据添加行锁， 在一个事务内， 只能由当前事务对其进行更新，  这样一来就不会有并发问题了。 但是这种方式相比于第一种方式， 额外的增加了行锁的持有时间， 在大量的并发更新时， 很有可能产生雪崩效应。</p>

<p>如果使用版本控制的乐观锁实现， 虽然也可以达到目的， 但是在大量并发的情况下可能会导致许多的更新都会失败， 而后全部进行重试流程， 导致恶性循环。</p>

<h4 id="4-事务隔离">4. 事务隔离</h4>

<p>在上面的讨论中， 不管是先更新， 还是先取出数据再更新， 都面临着同一个问题: 并发。 并发导致了SQL语句并不会向我们预期的那样执行， 前脚取出的数据可能后脚就被更新了。 所以我们需要一个机制来协助我们对抗并发， 事务。</p>

<p>单纯的事务仅具有原子性， 即要么全部成功， 要么全部失败的特性。 想要满足我们的需求还需要一定的事务隔离级别。</p>

<p><code class="highlighter-rouge">REPEATABLE READ</code>该事务隔离级别保证了在同一个事务内， 所读取到的数据不受其它事务语句的影响，  同样也是MySQL默认的事务隔离级别。</p>

<p>所以不管是先更新还是先取数据， 只要在同一个事务内执行， 就不会存在数据污染问题， 保证了数据的准确与完整性。</p>

<h4 id="5-aop的实现">5. AOP的实现</h4>
<p>面向切面编程更进一步地理解其实就是函数式编程， 纵观Spring Boot AOP以及Python中的装饰器， 都是函数的注册与调用， 只是语言间的具体实现不同而已。 Python存在<code class="highlighter-rouge">@</code>语法糖， 更加的灵活和方便。 而对于Golang和Java而言， 就需要自己进一步的进行函数封装和调用了。</p>

<p>包括像<code class="highlighter-rouge">hook</code>(钩子)一类的技术实现， 最终也是函数的注册与调用。 比如Django中的<code class="highlighter-rouge">singal</code>(信号量)， 虽然说是发布-订阅模式， 但是本质仍是函数的调用。 只不过没有把具体的逻辑写在一个地方， 而是使用某种其它方式进行解耦了而已。</p>

<p>所以， 写一个简单的AOP是一件非常easy的事情， 处理好异常和重试机制就好。</p>

<h4 id="6-日志存储源">6. 日志存储源</h4>

<p>一个系统中对数据处理优先程度是不同的， 类似于转账记录、红包使用记录等数据， 必须进行完备的数据持久化， 并且能够在灾难时进行迅速恢复。 此时可使用可靠性较强的关系型数据库， 如MySQL， PG等。</p>

<p>当数据的要求较低， 并且数量比较庞大时， 可采用Elasticsearch进行存储和查询。</p>

<p>那么业务层在具体实现时， 就需要能够支持多种日志存储源， 此时面向接口编程又是最佳的选择。</p>

<h4 id="7-持续优化">7. 持续优化</h4>

<p>前面提到了由于需要记录数据操作日志的原因， 需要在更新、删除等操作后多一次额外的数据查询， 并且需要将完整的日志数据持久化至日志存储源， 相当于多了两次网络传输。</p>

<p>如何将这两次网络传输所花费的时间降至最低， 是本小结要讨论的内容。</p>

<p>数据库数据组织形式分为聚集索引和非聚集索引， 聚集索引的组织方式使得B+Tree的叶子节点即数据， 而非聚集索引的叶子节点仍然是索引节点， 需要多一个I/O操作找到该索引节点的数据节点。 所以说， 使用主键查询是非常快的。</p>

<p>对于常见的更新操作， 通常不会使用主键来作为查找条件， 这是由业务系统所决定的。 所以说如果使用<code class="highlighter-rouge">更新-查询</code>的方式， 无法使用主键进行查询来提高系统效率。 相反， 使用<code class="highlighter-rouge">查询-更新</code>的方式却可以。 查询时使用非聚集索引进行查询， 而后使用主键来进行数据定位和更新。</p>

<p>日志持久化可使用消息队列完成， 重试机制可使用消息队列本身携带的重试实现， 或者是对其进行封装， 自行实现。</p>

<h4 id="8-批量更新问题">8. 批量更新问题</h4>
<p>如果需要更新的行数不止一条， 而是有很多条时又该如何处理? 取出数据后遍历更新并生成操作日志吗?</p>

<p>在业务端写SQL一个比较忌讳的事情就是在for循环中对数据库进行操作， 如此一来必定会有N次网络传输， 跑起来的效率令人发指。</p>

<p>可以采用<code class="highlighter-rouge">查询-业务端组装操作日志-更新</code>的方式完成， 伪代码如下:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 开启事务</span>
<span class="n">begin</span>

<span class="n">result_list</span> <span class="o">=</span> <span class="n">Model</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="c"># 生成批量日志</span>
<span class="n">log_list</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">instance</span> <span class="ow">in</span> <span class="n">result_list</span><span class="p">:</span>
    <span class="n">ins_dict</span> <span class="o">=</span> <span class="n">Serialize</span><span class="p">(</span><span class="n">instance</span><span class="p">)</span>
    <span class="c"># 填充ip, 操作人等信息</span>
    <span class="n">log_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ins_dict</span><span class="p">)</span>

<span class="c"># 对多条数据进行更新</span>
<span class="n">Model</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="n">commit</span> <span class="ow">or</span> <span class="n">rollback</span>

<span class="c"># 事务成功提交后将日志提交至存储层</span>
</code></pre></div></div>

<h4 id="9-小结">9. 小结</h4>

<p>记录操作日志这个需求看起来很小， 但是仔细的审视每一个操作内的细节， 会发现这真是一个有趣的需求。 涉及了数据库事务， 事务隔离， 索引， NoSQL与搜索引擎， 消息队列， 等等技术细节。</p>

	  ]]></description>
	</item>

	<item>
	  <title>那些有趣的数据结构与算法(05)--限流</title>
	  <link>//limits</link>
	  <author></author>
	  <pubDate>2019-07-20T21:54:55+00:00</pubDate>
	  <guid>//limits</guid>
	  <description><![CDATA[
	     <p>有时候限流也可以称为防刷， 这两者的界定并不是很明显， 常用的限流算法包括固定窗口， 滑动窗口， 漏桶以及令牌桶算法， 它们都有各自的优势与最适合的使用场景， 算法不分好坏， 之分场景。</p>

<!---more--->

<h4 id="1-固定窗口">1. 固定窗口</h4>
<p>固定窗口属于最简单但是也最容易出现问题的限流策略， 假设某接口限制请求频率为<code class="highlighter-rouge">10000/minute</code>， 则统计一分钟内接口请求的总次数， 若次数大于10000， 则请求失败， 开始限流， 直到下一个一分钟开始。</p>

<p>使用Redis可以非常轻松的实现该功能:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 该功能可用Lua优化，详见Lua模块</span>
<span class="kn">from</span> <span class="nn">redis</span> <span class="kn">import</span> <span class="n">Redis</span>
<span class="n">redis</span> <span class="o">=</span> <span class="n">Redis</span><span class="p">(</span><span class="s">"127.0.0.1"</span><span class="p">,</span> <span class="mi">6379</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">hit_user_access</span><span class="p">(</span><span class="n">api</span><span class="p">):</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">redis_key</span> <span class="o">=</span> <span class="s">"restrict_access:"</span><span class="o">+</span><span class="n">api</span>
        <span class="n">access_number</span> <span class="o">=</span> <span class="n">redis</span><span class="o">.</span><span class="n">incr</span><span class="p">(</span><span class="n">redis_key</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">access_number</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">redis</span><span class="o">.</span><span class="n">expire</span><span class="p">(</span><span class="n">redis_key</span><span class="p">,</span> <span class="mi">60</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">access_number</span> <span class="o">&gt;</span> <span class="n">MAX_ACCESS_NUMBER</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">True</span>
        <span class="k">return</span> <span class="bp">False</span>
    <span class="k">except</span> <span class="nb">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="c"># 日记记录</span>
        <span class="k">print</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
</code></pre></div></div>

<p>借助于Redis的expire-key功能来实现”当前一分钟”和”下一个一分钟”， 若键过期， 则重新进行计数， 表示下一个一分钟开始了。</p>

<p>固定窗口用来做小流量的防刷比较适合， 但是并不适合作为整体系统的限流。 其原因就在于在这一分钟内接收流量并不一定是平均的。 攻击方可以在每一个一分钟开始的前1秒或几秒中疯狂攻击接口， 使得接口的请求数量在一开始就达到上限， 这样一来后续的正常用户将无法访问。</p>

<p><img src="https://smartkeyerror.oss-cn-shenzhen.aliyuncs.com/jojo/system-design/limit/fixed.png" alt="" /></p>

<p>但是在一些简单的场景下， 例如单个用户的验证码发送条数限制， 当天密码输入失败的最大次数等等， 使用Redis实现的固定窗口不失为一个最佳选择。</p>

<h4 id="2-滑动窗口">2. 滑动窗口</h4>
<p>固定窗口很像一步接着一步的走路， 两步之间没有间隙， 但是每一步之间不会重叠。 而滑动窗口则是”拖着脚”在走路， 下一步会部分的覆盖前一步所走过的路径。</p>

<p><img src="https://smartkeyerror.oss-cn-shenzhen.aliyuncs.com/jojo/system-design/limit/moving-window.png" alt="" /></p>

<p>如上图所示， 窗口大小为60s， 每过一秒向前移动一小步， 60s过后将会移动一整个窗口， 此时就像固定窗口移动一样。</p>

<p>滑动窗口在限流上其实使用的不是很多， 原因就在于滑动窗口也无法处理1s内请求过载的问题，  但是在监控告警上却是不二之选。</p>

<p>滑动窗口的最大优势就在于”重叠”， 因为窗口在滑动过程中， 势必会跨越前一分钟和后一分钟， 使得控制更加精细。</p>

<p><img src="https://smartkeyerror.oss-cn-shenzhen.aliyuncs.com/jojo/system-design/limit/moving-window-alert.png" alt="" /></p>

<p>在具体的实现上， 通常会使用计算的方式来模拟窗口的向右滑动， 也可以说是”薛定谔的滑动”。 这里不考虑限流的滑动窗口实现， 而是转而实现监控告警的功能。</p>

<div class="language-lua highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">local</span> <span class="n">key</span> <span class="o">=</span> <span class="n">KEYS</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

<span class="kd">local</span> <span class="n">now_timestamp</span> <span class="o">=</span> <span class="nb">tonumber</span><span class="p">(</span><span class="n">ARGV</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="kd">local</span> <span class="n">window_size</span> <span class="o">=</span> <span class="nb">tonumber</span><span class="p">(</span><span class="n">ARGV</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
<span class="kd">local</span> <span class="n">limit</span> <span class="o">=</span> <span class="nb">tonumber</span><span class="p">(</span><span class="n">ARGV</span><span class="p">[</span><span class="mi">3</span><span class="p">])</span>

<span class="kd">local</span> <span class="n">should_clear</span> <span class="o">=</span> <span class="n">now_timestamp</span> <span class="o">-</span> <span class="n">window_size</span>
<span class="n">redis</span><span class="p">.</span><span class="n">call</span><span class="p">(</span><span class="s2">"ZREMRANGEBYSCORE"</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">should_clear</span><span class="p">)</span>

<span class="kd">local</span> <span class="n">amount</span> <span class="o">=</span> <span class="n">redis</span><span class="p">.</span><span class="n">call</span><span class="p">(</span><span class="s2">"ZCARD"</span><span class="p">,</span> <span class="n">key</span><span class="p">)</span>
<span class="k">if</span> <span class="n">amount</span> <span class="o">&lt;</span> <span class="n">limit</span> <span class="k">then</span>
    <span class="n">redis</span><span class="p">.</span><span class="n">call</span><span class="p">(</span><span class="s2">"ZADD"</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">now_timestamp</span><span class="p">,</span> <span class="n">now_timestamp</span><span class="p">)</span>
<span class="k">end</span>
<span class="n">redis</span><span class="p">.</span><span class="n">call</span><span class="p">(</span><span class="s2">"EXPIRE"</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">window_size</span><span class="p">)</span>

<span class="k">return</span> <span class="n">amount</span> <span class="o">&lt;</span> <span class="n">limit</span>
</code></pre></div></div>

<p>在熔断器里面会有这样的技术细节: 5分钟内失败率达到某个阈值时进行熔断， 像这样的需求完全可以使用滑动窗口很好的实现， 不管是使用简单的单机实现， 还是使用Redis的分布式实现。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">MovingWindow</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">window</span><span class="p">,</span> <span class="n">rate</span><span class="p">):</span>
        <span class="s">"""
        :param window: 窗口大小
        :param rate: 移动速率
        """</span>
        <span class="k">assert</span> <span class="n">window</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">rate</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="s">"window and rate should more than zero value"</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">window</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">rate</span><span class="p">,</span> <span class="nb">int</span><span class="p">),</span> <span class="s">"window and rate should be a Integer"</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">window</span> <span class="o">=</span> <span class="n">window</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rate</span> <span class="o">=</span> <span class="n">rate</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">__window</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">window</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__last_moving</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">())</span>

    <span class="k">def</span> <span class="nf">__shift</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">step</span><span class="p">):</span>
        <span class="s">"""
        :param step: 窗口向右滑动的距离
        """</span>
        <span class="k">if</span> <span class="n">step</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">window</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__clear</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__window</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__window</span><span class="p">[</span><span class="n">step</span><span class="p">:]</span> <span class="o">+</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">step</span>

    <span class="k">def</span> <span class="nf">__clock_shift</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="s">"""
        计算窗口应当滑动的距离
        """</span>
        <span class="n">now</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">())</span>
        <span class="n">expire</span> <span class="o">=</span> <span class="n">now</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">__last_moving</span>
        <span class="n">step</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">expire</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">rate</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">step</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__shift</span><span class="p">(</span><span class="n">step</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__last_moving</span> <span class="o">=</span> <span class="n">now</span>

    <span class="k">def</span> <span class="nf">incr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="c"># 首先将窗口滑动至正确位置</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__clock_shift</span><span class="p">()</span>
        <span class="c"># 将值添加至窗口最后一个元素上即可</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__window</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+=</span> <span class="n">value</span>

    <span class="k">def</span> <span class="nf">count</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="s">"""
        :return: 返回当前窗口计数总数
        """</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__clock_shift</span><span class="p">()</span>
        <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__window</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__clear</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__window</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">window</span>

    <span class="k">def</span> <span class="nf">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="s">"window: {}"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__window</span><span class="p">)</span>
</code></pre></div></div>

<h4 id="3-令牌桶">3. 令牌桶</h4>
<p>令牌桶算法可能是生产用使用的较为广泛的限流算法， 一方面可以限制瞬时流量， 一方面也可以限制一段时间内的流量， 算是比较两全的算法。</p>

<p>令牌桶引入缓冲区， 按照一定的速率生成令牌， 并将其置于令牌桶中。 每一个请求首先尝试从令牌桶中获取令牌， 若无令牌可用， 则直接返回失败。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">TokenBucket</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">capacity</span><span class="p">,</span> <span class="n">rate</span><span class="p">):</span>
        <span class="s">"""
        :param capacity: 桶的容量
        :param rate: 生成令牌的速率
        """</span>
        <span class="k">assert</span> <span class="n">capacity</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">rate</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="s">"capacity and rate should more than zero"</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">capacity</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">rate</span><span class="p">,</span> <span class="nb">int</span><span class="p">),</span> <span class="s">"capacity and rate should be integer"</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">capacity</span> <span class="o">=</span> <span class="n">capacity</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rate</span> <span class="o">=</span> <span class="n">rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__last_clock</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">())</span>
        <span class="c"># 初始令牌数为0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__bucket</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">def</span> <span class="nf">hit</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c"># 非并发安全的实现</span>
        <span class="n">now</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">())</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__bucket</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">capacity</span><span class="p">,</span> <span class="p">(</span><span class="n">now</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">__last_clock</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">rate</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">__bucket</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">True</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__bucket</span> <span class="o">-=</span> <span class="mi">1</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__last_clock</span> <span class="o">=</span> <span class="n">now</span>
            <span class="k">return</span> <span class="bp">False</span>
</code></pre></div></div>

<h4 id="4-小结">4. 小结</h4>
<p>无论是最简单的固定窗口， 还是稍微复杂一些的滑动窗口与令牌桶， 都有其适用的场景。 比如固定窗口适合限制具体的接口某个ip的访问次数， 滑动窗口用于记录一段时间内错误次数， 令牌桶用于秒杀场景下的限流。 在一个系统中综合运用这三种算法完全有可能， 只不过可能会根据业务场景的不同而进行稍加变动而已。</p>


	  ]]></description>
	</item>

	<item>
	  <title>那些有趣的数据结构与算法(04)--B-Tree与B+Tree</title>
	  <link>//B+Tree-and-B-Tree</link>
	  <author></author>
	  <pubDate>2019-06-23T16:01:47+00:00</pubDate>
	  <guid>//B+Tree-and-B-Tree</guid>
	  <description><![CDATA[
	     <p>树型结构由于其良好的递归特性， 高效的查询效率， 在软件系统设计中有着非常广泛的使用。 IO多路复用的epoll实现采用红黑树组织和管理sockfd， 以支持快速的增删改查； Golang中的Timer采用多叉堆实现； Java中的TreeMap以及TreeSet同样采用红黑树实现…而在MySQL中， 索引的构建同样采用树结构实现。</p>

<!---more--->

<h4 id="1-什么是b-tree">1. 什么是B-Tree</h4>
<p>B-Tree简单的来讲就是一颗矮胖的多叉平衡树， 通常不会超过3层。</p>

<p><img src="https://smartkeyerror.oss-cn-shenzhen.aliyuncs.com/Blog/index/B-Tree.png" alt="" /></p>

<p>如上图所示， 每一层均由指针， 索引值以及卫星数据组成。 进行搜索时， 同样采用二分查找的方式进行搜索， 所以搜索效率与树的高度直接相关， 这也是为什么B-Tree的树高非常少的原因， 其目的就在于提高搜索效率。</p>

<p>那么既然降低树高能够提高搜索效率， 为什么不干脆使用有序列表呢?</p>

<p><img src="https://smartkeyerror.oss-cn-shenzhen.aliyuncs.com/Blog/index/sorted-list.png" alt="" /></p>

<p>现在树高只有1， 搜索的平均时间复杂度即为<code class="highlighter-rouge">O(logn)</code>， 不是比B-Tree更快吗？ 有一个很关键的点就是， B-Tree是为了构建存储数据的索引而生， 数据量庞大且将会被持久化至磁盘或者SSD上。 如果说某一张表拥有过亿的数据量， 且服务器只有4G的内存， 根本无法将列表形式的索引完全载入内存， 二分查找也就无从说起。</p>

<h4 id="2-为硬盘存储而生的b-tree">2. 为硬盘存储而生的B-Tree</h4>
<p>已经9102年了， 服务器使用HDD作为持久层已经成为了一个过去式， 目前均采用SSD， 即固态硬盘作为持久层， 其读写效率约为HDD的10倍左右。</p>

<p><img src="https://smartkeyerror.oss-cn-shenzhen.aliyuncs.com/Blog/index/ssd-block.png" alt="" /></p>

<p>SSD简单的来看是由很多个Block(块)组成， 而Block又由很多个Page(页)所组成。 Page的大小通常为4K或者是8K， Blcok的大小通常为512K。</p>

<p>由于SSD没有向磁盘一样的悬臂， 所以不需要磁头的机械运动， 在读取数据时， 只需要找到数据所在的Block即可。 由于SSD特殊的组成方式， 在进行数据读取时， 其最小单位为Page， 也就是一次最小读取为4K或者是8K。 而对于删除数据来说， 其最小单位为Block， 因为需要进行加压擦除。</p>

<p>B-Tree之所以适合作为数据库索引结构的存储， 就是因为其矮胖的树型结构。 如果我们将索引树改为红黑树或者是AVL树这种二叉树的话， 会发生什么？</p>

<p><img src="https://smartkeyerror.oss-cn-shenzhen.aliyuncs.com/Blog/index/AVL-IO.png" alt="" /></p>

<p>假设树高为4， 所需的数据刚好位于AVL树的叶子节点， 那么在最坏的情况下(数据分散在不同的Page中)， 想要取出这条数据， 就需要4次的IO操作。 而IO操作， 相较于CPU的计算， 可以说慢如龟爬。 随着层高的增加， IO次数随线性增长， 这是我们不能接受的。</p>

<p>而对于B-Tree来讲， 就不会存在这样的问题， 因为其树高也就只有3、4层， 无论数据位于叶子节点还是非叶子节点， 其IO次数最多也只是4次而已。</p>

<h4 id="3-btree">3. B+Tree</h4>
<p>B+Tree是B-Tree的进化版， 目的在于进一步减少磁盘IO次数， 提供稳定的查询效率以及优化范围查找。</p>

<p>首先来看B+Tree的基本结构， 与B-Tree最大的不同就是: B+Tree的所有数据均保存在叶子节点， 非叶子节点只保存指针以及索引值。</p>

<p><img src="https://smartkeyerror.oss-cn-shenzhen.aliyuncs.com/Blog/index/Tree.png" alt="" /></p>

<p>如上图所示， 所有的数据均保存在B+Tree的叶子节点， 非叶子节点不保存数据， 这样一来使得在4K/Page的容量限制下， 能够保存更多的索引数量。 运气好的话原来使用B-Tree需要4层树高， 使用B+Tree的话可能只需要3层树高， 磁盘IO次数进一步降低了。</p>

<p>并且由于B+Tree只在叶子节点保存数据， 所以每一次查询都需要遍历至树底， 而所有叶子节点均处于同一层， 所以所有的查询时间复杂度都是相同的。</p>

<p>除此之外， 在叶子节点所有的数据均使用指针进行相连接， 也就是一个有序链表， 在进行范围查找时拥有极高的效率。 并不需要像B-Tree一样进行前序或者后序遍历。</p>

<h4 id="4-哈希索引">4. 哈希索引</h4>
<p>其实到这里有关B-Tree和B+Tree的内容就结束了， 但是还是忍不住再BB两句。</p>

<p>Hash Table是一种以空间换时间的数据结构， 底层由数组实现， 其平均查询时间复杂度为<code class="highlighter-rouge">O(1)</code>。 而B+Tree的平均查询时间复杂度为<code class="highlighter-rouge">O(logn)</code>， 那么索引为什么不使用哈希表， 而要使用B+Tree呢？</p>

<p>因为在数据库查询这一场景， 取出单一的一条数据这种需求占比并不会特别大， 更多的是使用某一种规则取出符合该规则的多条数据。 如果只是单一的一条数据， 那么哈希索引的效率确实要优于B+Tree。 但如果取出多条数据， 或者对数据进行排序的话， 那么B+Tree为更好的选择。</p>

<p>MySQL的InnoDB存储引擎只允许用户定义B+Tree索引， 不允许用户定义哈希索引， 就是因为无法判断用户是否能正确使用哈希索引。 但是InnoDB会根据实际情况自动地为某些数据添加哈希索引， 以增加查询速度。</p>

<h4 id="5-小结">5. 小结</h4>
<p>从B-Tree以及B+Tree的使用场景上来看， 没有适用于一切场景的数据结构， 只有最适合某些场景的数据结构。 在学习数据结构的过程中， 有时候不仅要关注它的原理， 更需要关注它的设计初衷以及适用场景。</p>

	  ]]></description>
	</item>

	<item>
	  <title>DevOps基础(1)--Shell脚本编程</title>
	  <link>//shell-programing</link>
	  <author></author>
	  <pubDate>2019-06-17T09:31:51+00:00</pubDate>
	  <guid>//shell-programing</guid>
	  <description><![CDATA[
	     <p>由于Docker容器以及Kubernetes容器编排服务的蓬勃发展， 服务器以及业务服务的运维不再是运维工程师的专属， 业务的开发工程师也必须加入到运维的领域之中， 与运维工程师合作， 形成一套完整、高效的自动化运维与部署的系统。 而在我看来， 传统的运维工程师将会逐渐被应用开发工程师所取代， 因为Kubernetes赋予了开发人员强大的负载均衡、自动横向拓展以及高效管理的相关功能。 而在这些宏大的系统建设之前， Shell编程是无论如何都离不开的话题。</p>

<!---more--->

<h4 id="1-shell变量">1. Shell变量</h4>
<p>作为一个后台开发人员， Shell脚本既陌生由熟悉， 毕竟Linux命令哪个后台开发不会接触呢？ 将一个又一个的Linux命令收集起来， 并使用一些粘合剂进行组合， 最终就得到了Shell脚本。</p>

<p>Shell和Python语言一样， 是一个弱类型语言， 也就是说一个变量可以对其进行任意的类型赋值:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>smart@Zero:~<span class="nv">$ foo</span><span class="o">=</span><span class="s2">"bar"</span>
smart@Zero:~<span class="nv">$ </span><span class="nb">echo</span> <span class="nv">$foo</span>
bar
smart@Zero:~<span class="nv">$ foo</span><span class="o">=</span>10
smart@Zero:~<span class="nv">$ </span><span class="nb">echo</span> <span class="nv">$foo</span>
10
</code></pre></div></div>

<p>在Terminal中， Shell命令就是一个天然的类似于Python的IPython环境， 如果我们想要对Python的某些语法进行测试的话， 需要进入Python或者IPython环境中， 而对于Shell而言， 打开Terminal就是自己工作的海洋。</p>

<p>在Shell中， 变量的赋值与其它语言没什么区别， 只不过获取变量的方式稍有不同而已。 我们可以认为<code class="highlighter-rouge">foo</code>变量是值<code class="highlighter-rouge">"bar"</code>的一个引用， 而要获取变量值， 需要借助引用名加上<code class="highlighter-rouge">$</code>符号， 非常类似C的指针。</p>

<p>在Shell编程的推荐使用方法中， 使用<code class="highlighter-rouge">${foo}</code>的方式获取变量内容， 多加一个大括号， 这样一来能够更加清楚的界定变量名称的范围， 不至于出现一些奇奇怪怪的问题。</p>

<p>除了我们自己定义的变量以外， 在Linux运行时， 还会预先定义一系列的环境变量。 环境变量说的简单一些就是定义在某一个文件中， 供整个Linux使用的变量， 可以认为是一种最高层的全局变量。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>smart@Zero:~<span class="nv">$ </span>env
...
<span class="nv">WORKON_HOME</span><span class="o">=</span>/home/smart/.virtualenvs
<span class="nv">HOME</span><span class="o">=</span>/home/smart
<span class="nv">PATH</span><span class="o">=</span>/home/smart/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/usr/local/go/bin/
</code></pre></div></div>

<p>获取当前系统的环境变量也简单， 敲<code class="highlighter-rouge">env</code>即可。 在上面的结果中， <code class="highlighter-rouge">WORKON_HOME</code>是virtualenvwrapper的工作目录， 是我定义在<code class="highlighter-rouge">~/.bashrc</code>中的， 而<code class="highlighter-rouge">HOME</code>和<code class="highlighter-rouge">PATH</code>变量， 则是Linux操作系统定义的。</p>

<p>获取系统的环境变量和获取自己定义的变量一样， <code class="highlighter-rouge">$</code>符+变量名:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>smart@Zero:~<span class="nv">$ </span><span class="nb">echo</span> <span class="nv">$HOME</span>
/home/smart
</code></pre></div></div>

<p>值得一提的就是<code class="highlighter-rouge">PATH</code>变量， 在安装一些软件时， 例如Java， Go时， 都需要将一些变量加入到<code class="highlighter-rouge">PATH</code>中， 为什么这么做？ Linux系统会在<code class="highlighter-rouge">PATH</code>变量值的路径中寻找可执行的二进制文件， 而当我们把诸如<code class="highlighter-rouge">GOPATH</code>的变量值假如到<code class="highlighter-rouge">PATH</code>变量中以后， 在任何的目录下， 都可以使用Go的相关命令， 这就是<code class="highlighter-rouge">PATH</code>变量的作用。</p>

<h4 id="2-获取系统函数的返回值">2. 获取系统函数的返回值</h4>
<p>诸如<code class="highlighter-rouge">cat</code>, <code class="highlighter-rouge">du</code>, <code class="highlighter-rouge">date</code>等命令， 实际上就是函数， 只不过是由C编写并通过某种方式暴露给用户而已。</p>

<p><code class="highlighter-rouge">date</code>函数用以获取当前时区的时间:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>smart@Zero:~<span class="nv">$ </span>date
2019年 05月 12日 星期日 10:43:48 CST
</code></pre></div></div>

<p>在编写Shell脚本时， 很多时候都需要将函数的运行结果保存在某一个变量中， 所以Shell提供了两种方式进行结果的赋值:</p>
<ol>
  <li>使用variable=&amp;#96date&amp;#96</li>
  <li>使用variable=$(date)</li>
</ol>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>smart@Zero:~<span class="nv">$ foo</span><span class="o">=</span><span class="sb">`</span>date<span class="sb">`</span>
smart@Zero:~<span class="nv">$ </span><span class="nb">echo</span> <span class="nv">$foo</span>
2019年 05月 12日 星期日 10:49:21 CST
smart@Zero:~<span class="nv">$ </span><span class="nb">echo</span> <span class="nv">$foo</span>
2019年 05月 12日 星期日 10:49:21 CST
</code></pre></div></div>

<p>如果查看<code class="highlighter-rouge">date</code>的manual手册的话， 会发现它还支持日期的格式化:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>smart@Zero:~<span class="nv">$ foo</span><span class="o">=</span><span class="sb">`</span>date +%y%m%d%H%M%S<span class="sb">`</span>
smart@Zero:~<span class="nv">$ </span><span class="nb">echo</span> <span class="nv">$foo</span>
190512105105
</code></pre></div></div>

<p>此外， Shell还提供了对上一个命令所执行结果的获取， 使用<code class="highlighter-rouge">$?</code>进行获取。 这是什么意思？ 在Shell中， 一条命令如果正常执行的话， 返回值将会是0， 如果命令执行时出现了某些错误的话， 返回值将会大于0， 且小于255。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 执行一条正常的命令</span>
smart@Zero:~<span class="nv">$ </span><span class="nb">echo</span> <span class="s2">"Hello World"</span>
Hello World
smart@Zero:~<span class="nv">$ </span><span class="nb">echo</span> <span class="nv">$?</span>
0

<span class="c"># 执行一条会抛出错误的命令</span>
smart@Zero:~<span class="nv">$ </span><span class="nb">ls</span> <span class="nt">-alh</span> NotExistFile
<span class="nb">ls</span>: cannot access <span class="s1">'NotExistFile'</span>: No such file or directory
smart@Zero:~<span class="nv">$ </span><span class="nb">echo</span> <span class="nv">$?</span>
2
</code></pre></div></div>

<p>由于NotExistFile是一个不存在的文件， 所以<code class="highlighter-rouge">ls</code>命令会产生一个标准错误并输出至屏幕中， 此时的退出状态码将会为2。 一些常见的退出状态码如下:</p>

<table>
  <thead>
    <tr>
      <th>状态码</th>
      <th>描述</th>
      <th>状态码</th>
      <th>描述</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>命令成功结束</td>
      <td>126</td>
      <td>命令不可执行</td>
    </tr>
    <tr>
      <td>1</td>
      <td>一般性未知错误</td>
      <td>127</td>
      <td>没找到命令</td>
    </tr>
    <tr>
      <td>2</td>
      <td>不合适的shell命令</td>
      <td>130</td>
      <td>通过Ctrl+C退出的命令</td>
    </tr>
  </tbody>
</table>

<h4 id="3-流程控制">3. 流程控制</h4>
<p>既然是一种语言， 又怎么能少的了流程控制。 在Shell脚本中， 使用最为广泛的恐怕就是<code class="highlighter-rouge">if-then</code>判断了。</p>

<h5 id="31-if-then">3.1 if-then</h5>
<p>条件语句的基本模板:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">if </span>command-1
<span class="k">then
  </span>command-2
<span class="k">else
  </span>command-3
<span class="k">fi</span>
</code></pre></div></div>

<p>需要特别注意的是， 这里的条件判断是command-1这条命令的执行结果: 如果command-1执行的退出状态码为0的话， 执行then语句块的内容， 否则退出。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/bin/bash</span>

<span class="k">if </span><span class="nb">ls</span> <span class="nt">-alh</span> NotExistFile
<span class="k">then
  </span><span class="nb">echo</span> <span class="s2">"The ls command exec successed"</span>
<span class="k">else
  </span><span class="nb">echo</span> <span class="s2">"Some error happened when exec ls"</span>
<span class="k">fi</span>
</code></pre></div></div>

<p>由于<code class="highlighter-rouge">ls -alh NotExistFile</code>的退出状态码为2， 所以将会输出”Some error happened when exec ls”。 如果我们想要true/false的条件语句， 使用<code class="highlighter-rouge">[[  ]]</code>。 例如， 如果变量<code class="highlighter-rouge">foo</code>的值为”bar”的话， 打印一条语句， 否则什么都不做:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/bin/bash</span>

<span class="nv">bar</span><span class="o">=</span><span class="s2">"foo"</span>
<span class="k">if</span> <span class="o">[[</span> <span class="k">${</span><span class="nv">bar</span><span class="k">}</span> <span class="o">=</span> <span class="s2">"foo"</span> <span class="o">]]</span>
<span class="k">then
  </span><span class="nb">echo</span> <span class="s2">"Right"</span>
<span class="k">fi</span>
</code></pre></div></div>

<p>与传统的语言都不同的是， 判断两个变量是否相等使用的是单个<code class="highlighter-rouge">=</code>号， 而不是<code class="highlighter-rouge">==</code>， 需要注意。</p>

<p>Shell也提供了一些参数来帮助我们进行条件判断， 例如<code class="highlighter-rouge">-n str</code>表示检查str的长度是否大于0， <code class="highlighter-rouge">-z str</code>表示检查str的长度是否为0， <code class="highlighter-rouge">-d file</code>用以检测file是否存在并且是一个目录, <code class="highlighter-rouge">-e file</code>判断file是否存在…</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">if</span> <span class="o">[[</span> <span class="nt">-n</span> <span class="k">${</span><span class="nv">bar</span><span class="k">}</span> <span class="o">]]</span>
<span class="k">then
  </span><span class="nb">echo</span> <span class="s2">"The length of the bar is not zero"</span>
<span class="k">fi

if</span> <span class="o">[[</span> <span class="nt">-d</span> <span class="s2">"/home/smart"</span> <span class="o">]]</span>
<span class="k">then
  </span><span class="nb">echo</span> <span class="s2">"/home/smart exist, and it's a directory"</span>
<span class="k">fi</span>
</code></pre></div></div>

<h5 id="32-case语句">3.2 case语句</h5>
<p>有时候变量的值会有多种， 如果一个一个的写<code class="highlighter-rouge">if</code>的话太麻烦了， 所以就有了<code class="highlighter-rouge">case</code>语句， 基本模板:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">case</span> variable <span class="k">in
</span>A <span class="p">|</span> B<span class="p">)</span> command-1 <span class="p">;;</span>
C<span class="p">)</span> command-2 <span class="p">;;</span>
D<span class="p">)</span> command-3 <span class="p">;;</span>
<span class="k">*</span><span class="p">)</span> default-command <span class="p">;;</span>
<span class="k">esac</span>
</code></pre></div></div>

<p>注意一下语法格式就好， 没有什么特别复杂的地方。</p>

<h5 id="33-while语句">3.3 while语句</h5>
<p>while语句的基本模板:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">while </span>condition
<span class="k">do
  </span><span class="nb">command
</span><span class="k">done</span>
</code></pre></div></div>

<p>condition的种类与<code class="highlighter-rouge">if-then</code>语法相同， 既可以判断命令的退出状态码， 也可以使用<code class="highlighter-rouge">[[  ]]</code>的形式来进行true/false判断:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 一个无限循环</span>
<span class="k">while</span> <span class="o">[[</span> <span class="nt">-n</span> <span class="k">${</span><span class="nv">bar</span><span class="k">}</span> <span class="o">]]</span><span class="p">;</span> <span class="k">do
    </span><span class="nb">echo</span> <span class="s2">"The length of bar is not zero"</span>
<span class="k">done</span>
</code></pre></div></div>

<h5 id="34-for循环">3.4 for循环</h5>
<p><code class="highlighter-rouge">for</code>循环的语法格式更贴近于Python， 其模板为:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for </span>var <span class="k">in </span>list
<span class="k">do
  </span><span class="nb">command
</span><span class="k">done</span>
</code></pre></div></div>

<p>例如使用通配符来生成文件列表， 然后遍历， 当遍历的文件是一个目录时， 打印它:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for </span>file <span class="k">in</span> /home/smart/<span class="k">*</span>
<span class="k">do
  if</span> <span class="o">[[</span> <span class="nt">-d</span> <span class="k">${</span><span class="nv">file</span><span class="k">}</span> <span class="o">]]</span>
  <span class="k">then
    </span><span class="nb">echo</span> <span class="s2">"</span><span class="k">${</span><span class="nv">file</span><span class="k">}</span><span class="s2"> is a directory"</span>
  <span class="k">fi
done</span>
</code></pre></div></div>

<p>也可以使用C语言风格的循环语句:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="o">((</span> i <span class="o">=</span> 0<span class="p">;</span> i &lt; 10<span class="p">;</span> i++ <span class="o">))</span><span class="p">;</span> <span class="k">do
    </span><span class="nb">echo</span> <span class="s2">"</span><span class="k">${</span><span class="nv">i</span><span class="k">}</span><span class="s2">"</span>
<span class="k">done</span>
</code></pre></div></div>

<h4 id="4-处理用户输入与重定向">4. 处理用户输入与重定向</h4>
<p>向脚本传递用户的参数是一个shell脚本最基本的操作， 脚本获取参数的方式也与其它语言不同。 诸如Java， 参数是以字符数组的方式传递给main函数的。</p>

<p>在shell中， 使用<code class="highlighter-rouge">$1</code>来获取第一个参数， <code class="highlighter-rouge">$2</code>获取第二个参数, …， <code class="highlighter-rouge">$n</code>获取第n个参数。 而<code class="highlighter-rouge">$0</code>比较特殊， 代表了执行该脚本的路径名称。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/bin/bash</span>
<span class="c"># test.sh</span>
<span class="nb">echo</span> <span class="k">${</span><span class="nv">0</span><span class="k">}</span>, <span class="k">${</span><span class="nv">1</span><span class="k">}</span>, <span class="k">${</span><span class="nv">2</span><span class="k">}</span>, <span class="k">${</span><span class="nv">3</span><span class="k">}</span>
</code></pre></div></div>

<p>在赋予了普通用户对该脚本的执行权限后， 执行该脚本: <code class="highlighter-rouge">./test.sh A B C</code>， 将会得到输出:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>./test.sh, A, B, C
</code></pre></div></div>

<p>对于<code class="highlighter-rouge">$0</code>， 如果只想要获取脚本名称的话， 可以使用<code class="highlighter-rouge">$(basename ${0})</code>。 获取参数个数使用<code class="highlighter-rouge">$#</code>， 获取所有参数使用<code class="highlighter-rouge">$*</code>或者是<code class="highlighter-rouge">$@</code>， 前者如果使用<code class="highlighter-rouge">"$*"</code>进行引用的话， 将会作为一个字符整体对待， 而<code class="highlighter-rouge">$@</code>不管在何种情况下， 都是参数所组成的列表， 所以<code class="highlighter-rouge">$@</code>更多的用于参数的迭代。</p>

<p>提到参数处理， 就不得不提及<code class="highlighter-rouge">shift</code>关键字。在使用<code class="highlighter-rouge">shift</code>命令时,默认情况下它会将每个参数变量向左移动一个位置。所以,变量$3的值会移到$2中,变量$2的值会移到$1中,而变量$1的值则会被删除。</p>

<p><code class="highlighter-rouge">shift</code>的测试也很简单， 非常清楚的就能够知道它到底做了什么:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/bin/bash</span>

<span class="nb">echo</span> <span class="s2">"All param: </span><span class="nv">$@</span><span class="s2">"</span>
<span class="nb">shift
echo</span> <span class="s2">"The first shift: </span><span class="nv">$@</span><span class="s2">"</span>
<span class="nb">shift
echo</span> <span class="s2">"The second shift: </span><span class="nv">$@</span><span class="s2">"</span>
<span class="nb">shift
echo</span> <span class="s2">"The third shift: </span><span class="nv">$@</span><span class="s2">"</span>
</code></pre></div></div>

<p>这次多传递一些参数进入该脚本， 得到的输出:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>smart@Zero:~<span class="nv">$ </span>./test.sh A B C D E F
All param: A B C D E F
The first <span class="nb">shift</span>: B C D E F
The second <span class="nb">shift</span>: C D E F
The third <span class="nb">shift</span>: D E F
</code></pre></div></div>

<p>每执行一次shift， 参数列表的首个参数都会被弹出， 如果执行<code class="highlighter-rouge">shift 2</code>的话， 将会弹出2个参数。</p>

<p>在<code class="highlighter-rouge">Ansible</code>的ad-hoc模式中， 通常我们会这样执行命令:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 将ansible所管理的所有主机进行文件拷贝, 并发数为10</span>
ansible all <span class="nt">-m</span> copy <span class="nt">-a</span> <span class="s2">"src=/home/smart/monitor/ dest=/home/monitor"</span> <span class="nt">-f</span> 5
</code></pre></div></div>

<p>在有了shift之后， 就可以很轻松的编写出对应的shell脚本了:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/bin/sh</span>
<span class="c"># simulate_ansible.sh</span>
<span class="c"># 运行: ./simulate_ansible.sh all -m copy -a "src=/home/smart/monitor/ dest=/home/monitor" -f 5</span>

<span class="nb">echo</span> <span class="s2">"Get params: </span><span class="nv">$@</span><span class="s2">"</span>
<span class="k">while</span> <span class="o">[[</span> <span class="nv">$# </span><span class="nt">-gt</span> 0 <span class="o">]]</span><span class="p">;</span> <span class="k">do
  case</span> <span class="nv">$1</span> <span class="k">in
  </span>all<span class="p">)</span>
    <span class="nb">echo</span> <span class="s2">"The process host group: </span><span class="k">${</span><span class="nv">1</span><span class="k">}</span><span class="s2">"</span>
    <span class="nb">shift</span> <span class="p">;;</span>
  <span class="nt">-m</span><span class="p">)</span>
    <span class="nb">echo</span> <span class="s2">"Get module name: </span><span class="k">${</span><span class="nv">2</span><span class="k">}</span><span class="s2">"</span>
    <span class="nb">shift </span>2 <span class="p">;;</span>
  <span class="nt">-a</span><span class="p">)</span>
    <span class="nb">echo</span> <span class="s2">"Get parameter: </span><span class="k">${</span><span class="nv">2</span><span class="k">}</span><span class="s2">"</span>
    <span class="nb">shift </span>2 <span class="p">;;</span>
  <span class="nt">-f</span><span class="p">)</span>
    <span class="nb">echo</span> <span class="s2">"The fork number is: </span><span class="k">${</span><span class="nv">2</span><span class="k">}</span><span class="s2">"</span>
    <span class="nb">shift </span>2 <span class="p">;;</span>
  <span class="k">*</span><span class="p">)</span>
    <span class="nb">echo</span> <span class="s2">"Bad params"</span>
    <span class="nb">exit </span>2
  <span class="k">esac
done</span>
</code></pre></div></div>

<p>在Linux I/O中， 标准输入使用0表示， 标准输出使用1表示， 标准错误使用2表示。 什么是标准输出/错误? 使用<code class="highlighter-rouge">ls</code>命令得到的结果就是标准输出， 使用<code class="highlighter-rouge">ls NotExistFile</code>命令得到的结果就是标准错误。</p>

<p>Shell脚本在执行时， 许多时候都是边缘触发或者是定时执行的， 其标准输出与错误我们是看不到的， 所以就需要有日志进行记录。 一个记录标准输出， 一个记录标准错误:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">ls</span> <span class="nt">-alh</span> NotExistFile 1&gt;~/monitor/stdout.log 2&gt;~/monitor/stderror.log
</code></pre></div></div>

<p>有时候想偷个懒， 不管是输出还是错误， 都重定向到同一个文件:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">ls</span> <span class="nt">-alh</span> &amp;&gt;~/homo/monitor/ls.log
</code></pre></div></div>

<h4 id="5-函数">5. 函数</h4>
<p>shell中的函数并没有很强大的功能， 更像是一个小型的shell脚本。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 定义</span>
funcname<span class="o">()</span> <span class="o">{</span>...<span class="o">}</span>
<span class="c"># 调用与参数传递</span>
funcname <span class="s2">"foo"</span> <span class="s2">"bar"</span>
</code></pre></div></div>

<h4 id="6-常见的shell脚本头设置">6. 常见的shell脚本头设置</h4>
<p>有时会看到在某些shell脚本中有这样的语句:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">set</span> <span class="nt">-e</span>
<span class="nb">set</span> <span class="nt">-x</span>
<span class="nb">exec</span> &amp;&gt; test.log
</code></pre></div></div>

<p><code class="highlighter-rouge">set</code>以及<code class="highlighter-rouge">exec</code>主要是对当前脚本的一些全局设置， 所以会放到脚本开始的地方。</p>

<p><code class="highlighter-rouge">set -e</code>表示如果当前的脚本在执行某一条命令时的退出状态码不为0时， 则整个脚本退出。 有些类似于异常的抛出与进程终止。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/bin/bash</span>
<span class="nb">set</span> <span class="nt">-e</span>
<span class="nb">ls</span> <span class="nt">-alh</span>
<span class="nb">ls</span> <span class="nt">-alh</span> NotExistFile
<span class="nb">echo</span> <span class="s2">"Done"</span>  <span class="c"># 永远不会执行到该行命令</span>
</code></pre></div></div>

<p><code class="highlighter-rouge">set -x</code>则主要用于进行DEBUG， 在脚本执行时将会打印出每一行命令执行的详细信息。</p>

<p><code class="highlighter-rouge">exec &amp;&gt; test.log</code>则表示将当前脚本执行时所产生的所有标准输出与错误均重定向至test.log文件。</p>

<h4 id="7-子shell">7. 子shell</h4>
<p>假如我们编写了这样的一个shell脚本:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/bin/bash</span>
<span class="nb">cd</span> /home/smart/monitor
</code></pre></div></div>

<p>然后执行该脚本， 会发现当前的目录并没有发生改变， 为什么? 这是因为不管是使用<code class="highlighter-rouge">bash script.sh</code>执行还是使用<code class="highlighter-rouge">./script.sh</code>来执行脚本， 脚本的执行都在一个名为子shell的shell环境中执行。 子shell中执行<code class="highlighter-rouge">cd</code>命令， 并不会影响到当前的shell状态。</p>

<h4 id="8-小结">8. 小结</h4>
<p>从我的工作经验上来看， 如果是开发来兼职做运维工作的话， 以上的内容完全能够解决日常中需要的运维场景。 Shell脚本语言本身比较简单， 其核心仍然是一个又一个的Linux系统命令， Shell语言只是作为粘合剂将这些命令组合起来形成一个整体而已。</p>

<p>PS: 留一张思维导图作为自己的复习参考</p>

<p><img src="https://smartkeyerror.oss-cn-shenzhen.aliyuncs.com/Blog/ShellScript.png" alt="" /></p>

	  ]]></description>
	</item>

	<item>
	  <title>DevOps基础(2)--Ansible自动化运维工具</title>
	  <link>//Ansible</link>
	  <author></author>
	  <pubDate>2019-06-17T08:33:42+00:00</pubDate>
	  <guid>//Ansible</guid>
	  <description><![CDATA[
	     <p>Shell脚本能够为我们提供一部分的系统运维功能， 例如定时任务， 由Jenkins所管理的边缘触发任务等等， 但是如果想要对多台服务器进行管理和运维， 就需要Ansible来协助完成。</p>

<!---more--->

<h4 id="1-ansible是什么">1. Ansible是什么?</h4>

<p>Ansible是一个由Python语言编写的自动化运维工具， 底层基于SSH框架， 帮助运维以及开发人员进行批量的服务器管理。</p>

<p>假设我们有10台服务器， 需要查看当前每台服务器的磁盘使用状况， 如果说采用传统的SSH登录， 然后输入密码， 进入远程服务器， 使用<code class="highlighter-rouge">df -h</code>来查看磁盘的使用状态的话， 这个过程需要持续10次。 就算我们将客户端的公钥上传至服务器使得我们可以免密登录远程服务器， 这个过程仍然是很花时间的。</p>

<p>此时Ansible就发挥其作用了， 由于Ansible是基于SSH框架所实现的， 所以Ansible可以批量的进行远程服务器的SSH连接， 在该连接之上执行<code class="highlighter-rouge">df -h</code>， 并将结果返回给客户端。 而且Ansible还提供了多进程的方式进行工作， 进一步的提升执行效率以及节省运维人员的时间。</p>

<h4 id="2-ansible的安装与配置">2. Ansible的安装与配置</h4>
<p>正如前面所提到的， Ansible是由Python所编写的工具， 那么自然需要相应的Python环境或者是Python的虚拟环境。 在Linux操作系统中， 本身就包含了python2.7以及python3.6+的环境， 所以如果不使用虚拟环境的话， 可以直接使用</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip install ansible
</code></pre></div></div>

<p>进行安装。 在安装完成后， 目录<code class="highlighter-rouge">/etc/ansible</code>即会生成。 在该目录下， 只有两个文件:</p>
<ul>
  <li>ansible.cfg: ansible的全局配置文件</li>
  <li>hosts: ansible默认的服务器配置文件， 有时又称为资产清单文件</li>
</ul>

<p>两个文件的配置都很简单且易懂。 对于hosts文件， 定义的格式以及具体的实例如下:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">[</span>group-name]
server-ip/server-domain <span class="nv">ansible_ssh_user</span><span class="o">=</span>USERNAME

<span class="o">[</span>local_server]
192.168.1.106 <span class="nv">ansible_ssh_user</span><span class="o">=</span>smart
</code></pre></div></div>

<p>在上面的实例中， 定义了<code class="highlighter-rouge">local_server</code>这个主机组， 在该组下只有一台主机， IP地址为192.168.1.106， 并定义了ansible在当前主机执行任务时的用户名称为smart。</p>

<p>而对于ansible.cfg文件， 更多的是定义默认的服务器配置文件路径， 执行的并发数， 以及客户端的公钥等。</p>

<p>为了能够使用公钥登录服务器， 得先将客户端的公钥上传至服务器的authorized_keys文件中， 这个过程可以交给ssh来自动完成:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ssh-copy-id user@server-ip
输入密码即可
</code></pre></div></div>

<p>将当前客户端的公钥地址配置在ansible.cfg中， 其余的配置保持默认即可:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">ansible_ssh_private_key_file</span><span class="o">=</span>/home/smart/.ssh/id_rsa.pub
</code></pre></div></div>

<h4 id="3-ansible的模块">3. ansible的模块</h4>

<p>对于一个任务而言， 需要的要素就是谁在哪儿做什么。 在Ansible自动化管理中， 当然是由Ansible来做了， 任务执行的范围即定义在hosts服务器配置文件之中， 剩下的就是定义具体的任务了。</p>

<p>Ansible提供了两种任务定义的方式， 一种叫ad-hoc， 一种叫playbooks。 ad-hoc就像是我们在Terminal中执行shell命令一样， 是一种临时的、无法保存成文件的任务执行方式。 而playbooks则是永久的、能够多次执行并保存成文件的任务， 相当于Shell脚本。</p>

<p>在前一篇Shell脚本的文章有提到， Shell脚本的核心是一条一条的Linux命令， Shell语言只是提供粘合剂将它们组合形成一个整体。 对于Ansible而言， 其核心就是模块， 而playbook则是将多个模块组合在一起。</p>

<p>那么Ansible模块又是什么? Ansible模块其实就是一个又一个的Python脚本， 为用户提供各种各样功能的脚本。 例如使用最为广泛的<code class="highlighter-rouge">copy</code>模块， 其作用是将本地的文件拷贝至服务器的目标目录中。</p>

<p>如果我们自己来完成文件拷贝的需求， 可以使用</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>scp file_path user@server-ip:server_path
</code></pre></div></div>

<p>如果是对很多台服务器进行文件拷贝的话， 可以使用一个Shell脚本来完成:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/bin/bash</span>
<span class="nb">set</span> <span class="nt">-xe</span>
<span class="nb">exec</span> &amp;&gt; /home/smart/shell/file-copy.log

<span class="nv">USER</span><span class="o">=</span><span class="s2">"admin"</span>
<span class="nv">LOCAL_PATH</span><span class="o">=</span><span class="s2">"/home/smart/monitor"</span>
<span class="nv">SERVER_PATH</span><span class="o">=</span><span class="s2">"/home/monitor"</span>

<span class="k">for </span>server <span class="k">in </span>server_list
<span class="k">do
  </span>scp <span class="nt">-R</span> <span class="k">${</span><span class="nv">LOCAL_PATH</span><span class="k">}</span> <span class="k">${</span><span class="nv">USER</span><span class="k">}</span>@<span class="k">${</span><span class="nv">server</span><span class="k">}</span>:<span class="k">${</span><span class="nv">SERVER_PATH</span><span class="k">}</span>
<span class="k">done</span>
</code></pre></div></div>

<p>而这么多行的Shell脚本， Ansible使用一个<code class="highlighter-rouge">copy</code>模块就可以完成， 这就是Ansible模块的威力。</p>

<p>如果使用Ansible命令行的模式来完成文件拷贝的任务， 只需要一行命令:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ansible all <span class="nt">-m</span> copy <span class="nt">-a</span> <span class="s2">"src=/home/smart/monitor dest=/home/monitor"</span> <span class="nt">-f</span> 6
</code></pre></div></div>

<p><code class="highlighter-rouge">all</code>表示对hosts文件中的所有主机执行任务， 也可以执行组名， 例如<code class="highlighter-rouge">local_server</code>。 <code class="highlighter-rouge">-m</code>指定模块名称， 这里选用<code class="highlighter-rouge">copy</code>模块。 <code class="highlighter-rouge">-a</code>添加模块所需要的参数， 而<code class="highlighter-rouge">-f</code>则指定并行的数量， 通常会和客户端的CPU核心数相同。</p>

<p>回到文章开始的地方， 对10台服务器执行<code class="highlighter-rouge">df -h</code>命令该怎么做? 由于这是一个Shell命令， 所以理所当然的使用<code class="highlighter-rouge">shell</code>模块， 传递给该模块的参数就是所要执行的命令:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ansible local_server <span class="nt">-m</span> shell <span class="nt">-a</span> <span class="s2">"df -h"</span>
</code></pre></div></div>

<p>将会得到这样的结果:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>192.168.1.106 | SUCCESS | <span class="nv">rc</span><span class="o">=</span>0 <span class="o">&gt;&gt;</span>
Filesystem      Size  Used Avail Use% Mounted on
udev            7.8G     0  7.8G   0% /dev
tmpfs           1.6G  2.2M  1.6G   1% /run
/dev/sdb3        95G   34G   57G  38% /
tmpfs           7.9G  265M  7.6G   4% /dev/shm
tmpfs           5.0M  4.0K  5.0M   1% /run/lock
tmpfs           7.9G     0  7.9G   0% /sys/fs/cgroup
</code></pre></div></div>

<p>Ansible和Shell一样， 提供了非常多封装了各种各样功能的模块， 到目前为止， Ansible大概提供了约2100个模块， 几乎涵盖了服务器运维的所有方面。 所以我认为这进一步地印证了在Ansible中， 最为重要的并不是如何编写playbooks， 而是如何在这2100个模块中找到自己想要的， 并正确的使用它。</p>

<blockquote>
  <p>Ansible所有模块文档地址: <a href="https://docs.ansible.com/ansible/latest/modules/list_of_all_modules.html">ansible list of modules</a></p>
</blockquote>

<h4 id="4-ansible-playbooks">4. Ansible playbooks</h4>
<p>通常来讲ad-hoc模式常常拿来做测试， 例如:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ansible all <span class="nt">-m</span> ping
</code></pre></div></div>

<p>来测试服务器的配置以及服务器的可达状态， 或者是说批量的添加用户并分配用户组等小功能。 在自动化部署这一需求下， 仍然会使用playbooks来组合测试、QA以及生产环境的相关任务。</p>

<p>在playbooks下有两个很重要的概念: roles， tasks。 roles是一个或多个任务(task)的集成， 表示当前的任务所运行的环境。 通常都会分为dev， test， QA， prod， 主要用于环境区分。 而tasks则是变量列表和具体的任务列表的集成， 代表了真正要执行的任务。 所以， 一个playbooks的结构往往是这样的:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>├── dev.yaml
├── inventory.cfg
├── prod.yaml
├── roles
│   ├── dev
│   │   ├── tasks
│   │   │   └── main.yaml
│   │   └── vars
│   │       └── main.yaml
│   ├── prod
│   │   ├── tasks
│   │   │   └── main.yaml
│   │   └── vars
│   │       └── main.yaml
│   └── <span class="nb">test</span>
│       ├── tasks
│       │   └── main.yaml
│       └── vars
│           └── main.yaml
└── test.yaml
</code></pre></div></div>

<p>看起来会很复杂， 其实非常的简单。 在根目录下， <code class="highlighter-rouge">dev|test|prod.yaml</code>是playbooks的主要入口文件， 而reoles目录下的<code class="highlighter-rouge">dev|test|prod</code>目录中则保存着对应环境的环境变量以及所要执行的任务。 <code class="highlighter-rouge">inventory.cfg</code>则保存着当前项目所设计的服务器资产清单， 包括开发， 测试， QA以及生产服务器的分组和ip。</p>

<h5 id="41-入口文件testyaml">4.1 入口文件test.yaml</h5>
<p>这里以<code class="highlighter-rouge">test.yaml</code>入口文件为例， 该配置文件其实非常的简单:</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="pi">-</span> <span class="na">hosts</span><span class="pi">:</span> <span class="s">test</span>
  <span class="na">roles</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="s">test</span>
</code></pre></div></div>

<p>没有更多内容了， 首先指定测试环境所用到的服务器组名， 其次指定测试环境的roles目录。 playbooks的运行是从入口文件开始的:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ansible-playbook <span class="nt">-i</span> inventory.cfg test.yaml
</code></pre></div></div>

<h5 id="42-任务列表文件">4.2 任务列表文件</h5>
<p>对于一个task.yaml而言， 也非常简单: 组合多个模块。</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">print current date</span>
  <span class="na">shell</span><span class="pi">:</span> <span class="s">date</span>

<span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">copy file</span>
  <span class="na">copy</span><span class="pi">:</span>
    <span class="na">src</span><span class="pi">:</span> <span class="s">/home/monitor/test.log</span>
    <span class="na">dest</span><span class="pi">:</span> <span class="s">/home/monitor</span>
</code></pre></div></div>

<p>只不过是将ad-hoc模式下变量传递的方式改写成yaml文件的格式而已， 本质上仍然是对模块的应用。 但是这种任务编写的方式提供了额外的拓展功能， 例如<code class="highlighter-rouge">chdir</code>改变当前任务的工作目录， <code class="highlighter-rouge">register</code>将当前任务的执行结果保存至某一个变量中， 可以用于后续的DEBUG。</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">print current date</span>
  <span class="na">shell</span><span class="pi">:</span> <span class="s">date</span>
  <span class="na">args</span><span class="pi">:</span>
    <span class="na">chdir</span><span class="pi">:</span> <span class="s">/home/monitor</span>
  <span class="na">register</span><span class="pi">:</span> <span class="s">date_result</span>
<span class="s">-debug</span><span class="pi">:</span> <span class="s">var=date_result</span>
</code></pre></div></div>

<h5 id="43-变量列表文件">4.3 变量列表文件</h5>
<p>出于编码的最佳规范， 一些变量或者是常量最好是保存至某一个文件中， 而后进行引用。 在playbooks中， 我们只需要将变量写入<code class="highlighter-rouge">vars/main.yaml</code>， 以及在<code class="highlighter-rouge">tasks/main.yaml</code>中使用即可， 至于中间是怎么工作的， 可以完全不用关心。</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># vars/main.yaml</span>
<span class="na">home_path</span><span class="pi">:</span> <span class="s">/home/smartkeyerror</span>

<span class="c1"># tasks/main.yaml</span>
<span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">ls home_path</span>
  <span class="na">shell</span><span class="pi">:</span> <span class="s">ls ""</span>
  <span class="c1"># 如果使用进行变量引用的话， 必须添加""</span>
</code></pre></div></div>

<p>既然变量文件使用yaml的数据格式进行写入， 那么就可以使用dict数据结构来进行变量引用:</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 定义</span>
<span class="na">foo</span><span class="pi">:</span>
  <span class="na">field1</span><span class="pi">:</span> <span class="s">A</span>
  <span class="na">field2</span><span class="pi">:</span> <span class="s">B</span>

<span class="c1"># 引用</span>
<span class="s">foo["field1"]</span>
<span class="s">foo.field1</span>
</code></pre></div></div>

<p>这种引用方式更多的是在模板(Template)中进行使用， <code class="highlighter-rouge">task.yaml</code>更多的是直接引用简单的变量。</p>

<h4 id="5-jinja2模板">5. Jinja2模板</h4>
<p>如果使用过Django或者是Flask等Python Web框架的小伙伴对Jinja2模板一定不会很陌生。</p>

<p>Ansible中的Jinja2模板并不是用于HTML文件的数据填充与渲染， 而是当做配置文件的模板进行远程配置文件的填充。</p>

<p>举一个并不是很恰当的例子， 但是能够说明问题。</p>

<p>假设有如下Nginx配置文件:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>server <span class="o">{</span>
    listen 80<span class="p">;</span>
    server_name gitlab.zero.com<span class="p">;</span>
    location / <span class="o">{</span>
        proxy_pass http://127.0.0.1:8181<span class="p">;</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div>

<p>一个非常简单gitlab端口转发配置， 现在我想要将<code class="highlighter-rouge">server_name</code>配置项的值放入到变量文件中， 然后将该配置文件上传至服务器中。 当然我们可以使用<code class="highlighter-rouge">copy</code>模块来完成， 但是copy模块没有办法在拷贝的文件中填充变量， 这个时候就需要使用到模板。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># nginx.gitlab.j2</span>

server <span class="o">{</span>
    listen 80<span class="p">;</span>
    server_name <span class="p">;</span>
    location / <span class="o">{</span>
        proxy_pass http://127.0.0.1:8181<span class="p">;</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div>

<div class="language-yml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">generate gitlab nginx config to server</span>
  <span class="na">template</span><span class="pi">:</span>
    <span class="na">src</span><span class="pi">:</span> <span class="s">./templates/nginx.gitlab.j2</span>
    <span class="na">dest</span><span class="pi">:</span> <span class="s">/etc/nginx/conf.d/gitlab.conf</span>
</code></pre></div></div>

<p>模板文件通常置于playbooks/templates目录中。 当执行完该playbooks之后， Ansible将会把填充好变量数据的Nginx配置文件置于应有的服务器目录下。</p>

<p>当然， Jinja2模板的功能远不止于此， 还可以在模板文件中添加条件判断以及数据的迭代:</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="p">{</span><span class="o">%</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">environment</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="o">%</span><span class="p">}</span>
    <span class="p">{{</span><span class="n">key</span><span class="p">}}:</span> <span class="s">"{{value}}"</span>
<span class="p">{</span><span class="o">%</span> <span class="n">endfor</span> <span class="o">%</span><span class="p">}</span>

<span class="p">{</span><span class="o">%</span> <span class="k">if</span> <span class="n">used_kafka</span> <span class="o">%</span><span class="p">}</span>
    <span class="o">...</span>
<span class="p">{</span><span class="o">%</span> <span class="n">endif</span> <span class="o">%</span><span class="p">}</span></code></pre></figure>

<h4 id="6-ansible-vault对变量文件进行加密">6. Ansible Vault对变量文件进行加密</h4>

<p>有时为了保证变量文件的安全性， 以及在网络传输时的隐蔽性， 通常都需要对变量文件进行加密， 只有在使用变量文件时才对其进行解密。</p>

<p><code class="highlighter-rouge">ansible-vault</code>命令就是Ansible提供给我们对文件进行加密的工具。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 变量文件只有一个变量配置</span>
smart@Zero:~<span class="nv">$ </span><span class="nb">cat </span>main.yaml
server_name: gitlab.zero.com

<span class="c"># 使用ansible-vault encrypt file进行加密</span>
smart@Zero:~<span class="nv">$ </span>ansible-vault encrypt main.yaml
New Vault password:
Confirm New Vault password:
Encryption successful

<span class="c"># 再次查看main.yaml</span>
smart@Zero:~<span class="nv">$ </span><span class="nb">cat </span>main.yaml

<span class="nv">$ANSIBLE_VAULT</span><span class="p">;</span>1.1<span class="p">;</span>AES256
31356236643435613539353331383734376438373966393064666538636635643934663736636437
3961316333633462376234386437346462333539393039310a663932663832306464316435646539
36636665366233343266386466313831343165303238623163373237313764333363373662303862
3561646430623230620a663964363462366435386139383666356330333336343535373336346232
36386236373639666633666130653861636530613034623635626135313130366632
</code></pre></div></div>

<p>在这里使用了手工输入密码的方式进行加密与解密， 除此之外还可以将密码写入文件， 在进行加密解密时执行文件:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 生成密码文件</span>
smart@Zero:~<span class="nv">$ </span><span class="nb">echo</span> <span class="s2">"mypassword"</span> <span class="o">&gt;</span> .password.conf

<span class="c"># 修改文件权限以及所属用户组</span>
smart@Zero:~<span class="nv">$ </span><span class="nb">sudo </span>chmod 600 .password.conf
smart@Zero:~<span class="nv">$ </span><span class="nb">sudo </span>chmod 600 .password.conf

<span class="c"># 加密</span>
smart@Zero:~<span class="nv">$ </span><span class="nb">sudo </span>ansible-vault encrypt <span class="nt">--vault-id</span> .password.conf main.yaml

<span class="c"># 解密</span>
smart@Zero:~<span class="nv">$ </span><span class="nb">sudo </span>ansible-vault decrypt <span class="nt">--vault-id</span> .password.conf main.yaml
</code></pre></div></div>

<h4 id="7-小结">7. 小结</h4>

<p>以上就是Ansible的核心内容， 不会特别的复杂， 但是由于模块众多的原因， 还是需要花时间去阅读具体的模块文档。</p>

<p>可以看到， Ansible真的就只是一个能够在多台主机上执行同一个任务的运维工具而已。 而在我看来， 运维最重要的并不是工具， 而是运维的体系。</p>

<p>在接下来的文章中可以看到， 当我们使用了Docker容器以后， 一个真正的自动化运维体系才算刚刚开始。 如果更进一步地使用Kubernetes的话， 甚至可以不需要Ansible。</p>

	  ]]></description>
	</item>

	<item>
	  <title>操作系统原理(01)-I/O</title>
	  <link>//operation-system-with-IO</link>
	  <author></author>
	  <pubDate>2019-04-15T10:17:46+00:00</pubDate>
	  <guid>//operation-system-with-IO</guid>
	  <description><![CDATA[
	     <p>在写了许多代码， 搭建了一些分布式服务之后， 越发觉得一个大型的高并发系统就是一个操作系统。 在分布式系统中， 我们会讲数据一致性， 如何做到缓存和DB的一致性， 这也是操作系统需要解决的问题: 内核高速页缓存如何与磁盘文件数据一致。 又比如对于一些耗时且非必需的任务， 在分布式系统中很有可能采用消息队列来进行异步处理， 例如邮件的发送， 而在操作系统中， I/O也是一个非常耗时的任务， 同样采用了异步处理的方式来最大化的利用系统资源， 只不过并不是采用消息队列而已。</p>

<!---more--->

<h4 id="1-uninx操作系统架构方式">1. Uninx操作系统架构方式</h4>

<p><img src="https://smartkeyerror.oss-cn-shenzhen.aliyuncs.com/Blog/IO/Uninx%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E6%96%B9%E5%BC%8F.png" alt="" /></p>

<p>如上图所示， 由于本篇文章只关心I/O， 所以只对I/O相关的内容进行了高亮处理。 操作系统的作用之一就是帮助用户管理硬件设备， 给程序员提供良好， 清晰， 优雅和一致的抽象接口。 所以， 在User Space和Hardware之间， 是由操作系统(即Kernel)进行协调的。</p>

<h4 id="2-io硬件原理">2. I/O硬件原理</h4>

<h5 id="21-io设备">2.1 I/O设备</h5>

<p>对于I/O设备而言， 通常可以分为两类: 块设备(block device)和字符设备(character device)。 块设备将信息存储在固定大小的块中， 每个块有自己的地址， 例如硬盘， U盘。 字符设备以字符为单位发送或者接收一个字符流， 不考虑任何块结构。 字符设备是不可寻址的， 也没有任何的寻道操作， 例如网卡。</p>

<h5 id="22-io设备硬件组成">2.2 I/O设备硬件组成</h5>
<p>I/O设备通常会由机械部件和电子部件组成。 机械部件为数据存储或者是数据暂存的物理介质。 电子部件我们更喜欢称之为设备控制器或者是适配器。</p>

<p>设备控制器的任务是把串行的位流转换为字符串， 并进行必要的错误校正工作。 字节块通常首先在控制器内部的一个缓冲区中按位进行组装， 然后在对校验和进行校验并证明字节快没有错误后， 再将其复制到主存中。</p>

<p>在TCP/UDP协议中， 都会有校验和来对网络传输过来的数据进行校验， 这是最低级别的校验， 通常就会在网卡， 或者说网络适配器中进行校验。</p>

<p><img src="https://smartkeyerror.oss-cn-shenzhen.aliyuncs.com/Blog/IO/%E7%A1%AC%E4%BB%B6%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86.png" alt="" /></p>

<h5 id="23-直接存储器存取">2.3 直接存储器存取</h5>
<p>当CPU采用内存映射I/O的方式找到了与之交换数据的控制器之后， 剩下的就是数据的存取了。</p>

<p>如果不借助任何外部硬件设备， 那么整个读取数据的过程为: CPU发出指令， 将磁盘中的某一块数据读入内存中。 磁盘的设备控制器接收到指令之后， 对磁盘进行磁臂调度， 并读取数据至设备缓冲区中进行校验， 校验通过后通过总线将数据传输至内存中。 由于CPU， 内存和磁盘之间的处理速度存在着巨大差异， 从发出指令开始， 到数据写入内存， 对于CPU而言可能觉得过了几年之久。</p>

<p>也就是说， 在CPU眼中， 处理指令只需要泡杯咖啡的时间， 而硬盘却花了几年的时间去完成。 这是CPU无法忍受的， 并且计算机系统也无法忍受， 因为在这个过程中， CPU就干等着， 什么事都做不了。</p>

<p>如果对CPU和磁盘之间的速度差仍然没有直观的感受的话， 不妨做一个数学题。 就博主电脑而言， CPU为I5 9400f， 一般运行时的频率为3.8GHZ， 也就是说在一秒的时间内能够处理<code class="highlighter-rouge">3.8*10^9</code>个指令， 每个指令平均耗时0.26纳秒。 SSD使用三星970 evo， 读取速度大概在2500M/S， 所以读取10M的数据需要0.004s,  <code class="highlighter-rouge">4*10^6</code>纳秒。 一个是0.26纳秒， 一个是4000000纳秒。 即使是三星970 evo， 读取速度达到2500M/S， 和CPU之间的差距依然是巨大的， 更不要提传统的机械硬盘了。</p>

<p>因此， 为了提高CPU的使用率， 硬件开发者为CPU找了一个帮手: 直接存储器(Direct Memory Access, DMA)。 DMA能够独立于CPU工作， 在有了DMA之后， I/O操作真正的实现了异步处理。</p>

<p><img src="https://smartkeyerror.oss-cn-shenzhen.aliyuncs.com/Blog/IO/DMA.png" alt="" /></p>

<ol>
  <li>当CPU要读取文件时， 对DMA控制器中的寄存器进行编程， 将要读的文件地址， 字节数等数据传入DMA控制器寄存器中。 此时CPU进行进程或者是线程切换， 调度其它任务的执行。</li>
  <li>DMA控制器接收指令后向磁盘设备控制器请求数据， 并要求磁盘将数据写入到内存的一块区域内。</li>
  <li>磁盘设备控制器调用磁盘驱动程序进行数据读取， 在磁盘缓冲区组装并检验完成后， 通过总线将数据写入内存中。</li>
  <li>写入完成后磁盘设备控制器通过总线向DMA发送信号， 告之以完成相关操作。</li>
  <li>DMA控制器发起硬件中断， 如果CPU此时能够处理中断， 则处理该中断， 并完成文件读操作。</li>
</ol>

<p>通常来讲DMA控制器会直接集成至主板中， 不需要额外的热拔插。 在有了DMA协助之后， CPU无需等待整个I/O过程的结束， 而是发出一条指令后去做其它的事情， 实现了真正的并行处理。</p>

<h5 id="24-中断异常机制">2.4 中断/异常机制</h5>
<p>在上面使用了DMA的I/O中， DMA控制器是通过中断来通知CPU事件的， 而中断机制， 正是操作系统的一个非常非常重要的组成部分。</p>

<p>正是因为有了中断/异常机制， 才能够使得CPU与设备之前的并行操作。 并且， 用户在使用计算机操作系统时， 许多行为都是不可预测的， 操作系统不知道什么时候会读写文件， 什么时候会有网络数据的到来， 什么时候用户会从键盘中进行输入。 所以， 操作系统从某些方面而言， 是由中断或者是驱动的。</p>

<p>当设备(磁盘， 网卡， 键盘等)发起中断后， 如果CPU能够处理中断， 那么它就会暂停正在执行的程序， 保留现场后自动转去执行相应事件的处理程序， 处理完成后返回断点继续执行被打断的程序。</p>

<p>中断通常是由外部事件所触发， 例如DMA控制器的中断， 时钟中断或者是硬件故障产生的中断。 而异常往往是由正在执行的指令触发， 例如系统调用(用户态转为内核态, 0x80指令)， 缺页故障， 断点指令(例如程序员的断点调试)等。</p>

<h4 id="3-io软件原理">3. I/O软件原理</h4>
<p>在硬件上， 有DMA协助CPU完成并行处理， 那么软件层面的I/O又是如何实现的?</p>

<h5 id="31-c标准io库">3.1 C标准I/O库</h5>
<p>在第一小节”Uninx操作系统架构方式”一图中可以看到， 用户想要调用系统函数有两种方式， 第一种就是调用C标准库函数， 第二种就是直接进行系统调用。 简单的来讲， 在所有支持C语言的平台上， 都可以调用C标准库函数， 也就是调用方式是完全相同的， 并不区分是Unix系统还是Windows系统。 而直接进行系统调用时， 由于操作系统实现的区别， 在Uninx操作系统中使用<code class="highlighter-rouge">read/write</code>函数， 而在Windows操作系统中， 则是使用<code class="highlighter-rouge">ReadFile/WriteFile</code>函数。 所以说， 直接进行系统调用会有平台移植的问题。</p>

<p>由于本篇文章着重于原理的解释， 所以对于与I/O相关的C标准库函数不会做过多介绍。 感兴趣的读者可以参阅《Uninx环境高级编程》。</p>

<p><code class="highlighter-rouge">fgets</code>函数从制定的文件中读一行字符到调用者提供的缓冲区中:</p>

<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp"># include&lt;stdio.h&gt;
</span>
<span class="kt">char</span> <span class="o">*</span><span class="n">fgets</span><span class="p">(</span><span class="kt">char</span> <span class="o">*</span><span class="n">s</span><span class="p">,</span> <span class="kt">int</span> <span class="n">size</span><span class="p">,</span> <span class="kt">FILE</span> <span class="o">*</span><span class="n">stream</span><span class="p">);</span>
</code></pre></div></div>

<p>参数s是缓冲区的首地址， 就是一个数组指针， size是缓冲区的长度， 该函数从stream所指的文件中读取以<code class="highlighter-rouge">\n</code>结尾的一行(包括<code class="highlighter-rouge">\n</code>)到缓冲区s内， 并且在该行末尾添加一个<code class="highlighter-rouge">\0</code>组成的完整字符串。</p>

<h5 id="32-c标准io库的缓冲区">3.2 C标准I/O库的缓冲区</h5>
<p>再来说说C标准库的I/O缓冲区， 当用户程序调用C标准I/O库函数读写文件或者是设备， 这些库函数要通过系统调用把读写请求传送给内核， 最终由内核驱动磁盘或者是设备完成I/O操作。</p>

<p>以<code class="highlighter-rouge">fgets</code>函数为例， 当用户程序第一次调用<code class="highlighter-rouge">fgets</code>函数读取一行数据时， <code class="highlighter-rouge">fgets</code>函数可能通过系统调用进入内核读取1k字节到I/O缓冲区中， 然后返回I/O缓冲区的第一行给用户， 把读写位置指向I/O缓冲区的第二行， 以后用户再调用<code class="highlighter-rouge">fgets</code>， 就直接从I/O缓冲区中读取， 而不需要再陷入内核进行读取。 当用户把这1K字节全部读完之后， 再次调用<code class="highlighter-rouge">fgets</code>时才会进入内核读取。</p>

<p>C标准库的I/O缓冲区也在用户空间， 直接从用户空间读取数据要比进入内核读取数据快得多。 另外， 如果用户调用<code class="highlighter-rouge">fputs</code>函数进行数据写入的话， 数据也只需要写到I/O缓冲区， <code class="highlighter-rouge">fputs</code>函数可以很快返回。 如果I/O缓冲区已经满了的话， <code class="highlighter-rouge">fputs</code>通过系统调用将缓冲区中的数据传入内核缓冲区中， 由内核决定何时将数据持久化至磁盘中。</p>

<p><img src="https://smartkeyerror.oss-cn-shenzhen.aliyuncs.com/Blog/IO/C%E6%A0%87%E5%87%86%E5%BA%93%E7%BC%93%E5%86%B2%E5%8C%BA.png" alt="" /></p>

<h5 id="33-unbuffered-io函数">3.3 Unbuffered I/O函数</h5>
<p>需要注意的是， Unbuffered I/O函数是由操作系统所提供的， 位于C标准库的I/O缓冲区的底层， 也就是说， C标准I/O库函数是调用操作系统所提供的无缓冲I/O工作的。 在Uninx中， 常见的无缓冲I/O函数为<code class="highlighter-rouge">open</code>, <code class="highlighter-rouge">read</code>, <code class="highlighter-rouge">write</code>, <code class="highlighter-rouge">close</code>等。</p>

<p><img src="https://smartkeyerror.oss-cn-shenzhen.aliyuncs.com/Blog/IO/UnbufferedIO .png" alt="" /></p>

<p>另外需要注意的是， 这里的无缓冲I/O函数指的是没有在用户空间开辟I/O缓冲区， 并不代表不使用缓冲区。 因为不管使用带缓冲的I/O函数， 还是Unbuffered I/O函数， 在内核空间中都会有I/O缓冲区。</p>

<p>现在问题来了， 用户什么时候应该选用C标准I/O库函数， 什么时候又该使用Unbuffered I/O函数呢?</p>

<ol>
  <li>使用Unbuffered I/O函数每次文件的读写都会进入内核， 调用一个系统函数要比调用一个用户空间的函数更为耗时， 所以在用户空间开辟I/O缓冲区还是很有必要的， 使用C标准I/O库函数非常的方便， 省去了自己管理I/O缓冲区的麻烦。</li>
  <li>在使用C标准I/O函数时， 由于数据是首先写入I/O缓冲区， 当缓冲区满时才会写入内核缓冲区， 所以会出现与实际文件数据不一致的情况， 在必要时调用<code class="highlighter-rouge">fflush</code>将数据强制刷入内核缓冲区中。</li>
  <li>在向网络设备写数据时我们希望数据能够通过网络及时的发送出去， 当设备接收到数据时应用程序也希望第一时间被通知到， 所以在网络编程中通常直接调用Unbuffered I/O函数。</li>
</ol>

<h4 id="4-内存映射文件">4. 内存映射文件</h4>
<p>内存映射， 简而言之就是将内核空间的一段内存区域映射到用户空间。 映射成功后， 用户对这段内存区域的修改可以直接反映到内核空间。 相反， 内核空间对这段区域的修改也直接反映用户空间。 那么对于内核空间与用户空间两者之间需要大量数据传输等操作的话效率是非常高的。 当然， 也可以将内核空间的一段内存区域同时映射到多个进程， 这样还可以实现进程间的共享内存通信。</p>

<p>系统调用<code class="highlighter-rouge">mmap()</code>就是用来实现上面所说的内存映射。 最常见的就是文件的操作， 可以将某文件映射至内存(进程空间)， 然后就可以把对文件的操作转为对内存的操作， 以此避免更多的<code class="highlighter-rouge">lseek()</code>与<code class="highlighter-rouge">read()</code>、<code class="highlighter-rouge">write()</code>操作， 因此， 在操作大文件或者是需要频繁的访问某一个文件时， 内存映射文件尤为高效。</p>

<p>这里给出一段python程序实例， 其实就是《Python Cookbook》中的例子:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">mmap</span>

<span class="k">def</span> <span class="nf">memory_map</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">access</span><span class="o">=</span><span class="n">mmap</span><span class="o">.</span><span class="n">ACCESS_WRITE</span><span class="p">):</span>
    <span class="n">size</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">getsize</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
    <span class="n">fd</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">O_RDWR</span><span class="p">)</span>  <span class="c"># O_RDWR即ReadWrite</span>
    <span class="k">return</span> <span class="n">mmap</span><span class="o">.</span><span class="n">mmap</span><span class="p">(</span><span class="n">fd</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">access</span><span class="o">=</span><span class="n">access</span><span class="p">)</span>

<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">"__main__"</span><span class="p">:</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">memory_map</span><span class="p">(</span><span class="s">"data.txt"</span><span class="p">)</span>
    <span class="n">m</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">11</span><span class="p">]</span> <span class="o">=</span> <span class="n">b</span><span class="s">"Hello World"</span>
    <span class="n">m</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</code></pre></div></div>

<p>需要注意的是， 对某个文件进行内存映射并不会导致整个文件被读入内存， 也就是说， 文件并不会拷贝到某种内存缓冲区或者是数组上。 操作系统仅仅只是为文件内容保留一段虚拟内存而已(虚拟内存: 磁盘与内存的交换技术)。 当程序访问文件的不同区域时， 文件的这些区域将被读取并按照需要映射到内存区域中。 但是， 文件中从未访问过的部分会简单的留在磁盘上， 并不会进入内存区域。</p>

<p>所以说， <code class="highlighter-rouge">mmap</code>拥有处理大文件的高效能力， 因为数据不再需要从内核空间拷贝至用户空间， 而是进行数据的映射。</p>

<h4 id="5-sendfile">5. sendfile</h4>
<p>关于<code class="highlighter-rouge">sendfile</code>函数的内容， 在<a href="https://smartkeyerror.com/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0-04-Nginx.html">分布式系统基础学习(04)–Nginx</a>这一博文中已有描述， 此处不再赘述。</p>

<h4 id="6-阻塞与非阻塞">6. 阻塞与非阻塞</h4>
<p>为了引出事件驱动I/O模型， 关于阻塞和非阻塞的概念仍然有必要再次进行整理。</p>

<p>首先需要明确阻塞(Block)的概念。 当进程调用一个阻塞的系统函数时， 该进程被置于睡眠(Sleep)状态， 此时内核调度其它进程运行， 直到该进程的事件发生了(例如DMA发起网络传输包到来的中断， 时钟发起中断)它才<strong>有可能</strong>继续运行。</p>

<p>与睡眠状态相对的是运行(Running)状态和就绪状态(Ready)。运行状态是指进程正在被调度执行， CPU处于该进程的上下文环境中， 程序计数器里保存着该进程的指令地址， 通用寄存器里保存着该进程运算的中间结果， 正在执行该进程的指令， 正在读写该进程的地址空间。</p>

<p>就绪状态是指该进程不需要等待什么事情发生， 随时都可以执行， 只不过此时CPU还在执行另一个进程， 所以该进程在一个就绪队列中等待被内核调度。</p>

<p><img src="https://smartkeyerror.oss-cn-shenzhen.aliyuncs.com/Blog/IO/%E8%BF%9B%E7%A8%8B%E7%8A%B6%E6%80%81%E7%9A%84%E8%BD%AC%E6%8D%A2.png" alt="" /></p>

<p>通常来讲， 调用系统函数<code class="highlighter-rouge">read</code>读取终端或者是网络设备数据时， 会被阻塞。 但是在<code class="highlighter-rouge">open</code>一个设备时指定了<code class="highlighter-rouge">O_NONBLOCK</code>标识， <code class="highlighter-rouge">read/write</code>就不会阻塞。 以<code class="highlighter-rouge">read</code>为例， 如果设备暂时没有数据可读就返回-1， 同时设置<code class="highlighter-rouge">errno</code>为<code class="highlighter-rouge">EWOULDBLOCK</code>， 表示本来应该阻塞在这里， 但是实际上并没有阻塞而是直接返回错误， 调用者应该试着再读一次， 这种方式称为轮询(Poll)。</p>

<p><strong>非阻塞I/O通常被用来监视多个设备的数据读取， 单独的I/O读取意义不大， 除非读取的内容与程序下文没有直接的联系</strong>。</p>

<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">while</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="err">非阻塞</span><span class="n">read</span><span class="p">(</span><span class="err">设备</span><span class="mi">1</span><span class="p">);</span>
    <span class="k">if</span><span class="p">(</span><span class="err">设备</span><span class="mi">1</span><span class="err">有数据到达，</span> <span class="err">处理数据</span><span class="p">);</span>

    <span class="err">非阻塞</span><span class="n">read</span><span class="p">(</span><span class="err">设备</span><span class="mi">2</span><span class="p">);</span>
    <span class="k">if</span><span class="p">(</span><span class="err">设备</span><span class="mi">2</span><span class="err">有数据到达，</span> <span class="err">处理数据</span><span class="p">);</span>

    <span class="p">...</span>
<span class="p">}</span>
</code></pre></div></div>

<p>这种方式有一个比较大的缺点就是当所有的设备都没有数据到达时， 调用者反复查询做无用功， 白白浪费CPU资源。 如果说加上延时， 例如:</p>

<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">while</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="err">非阻塞</span><span class="n">read</span><span class="p">(</span><span class="err">设备</span><span class="mi">1</span><span class="p">);</span>
    <span class="k">if</span><span class="p">(</span><span class="err">设备</span><span class="mi">1</span><span class="err">有数据到达，</span> <span class="err">处理数据</span><span class="p">);</span>

    <span class="err">非阻塞</span><span class="n">read</span><span class="p">(</span><span class="err">设备</span><span class="mi">2</span><span class="p">);</span>
    <span class="k">if</span><span class="p">(</span><span class="err">设备</span><span class="mi">2</span><span class="err">有数据到达，</span> <span class="err">处理数据</span><span class="p">);</span>

    <span class="p">...</span>

    <span class="n">sleep</span><span class="p">(</span><span class="n">n</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div></div>

<p>虽然能够解决一些CPU资源问题， 但是<code class="highlighter-rouge">n</code>如何选取? 并且如果程序刚刚进入睡眠， 设备1的数据就准备完毕了， 那么程序也要至少等待n秒才能处理， 此时处理的延迟将会非常之大。 所以， 才会有<code class="highlighter-rouge">select</code>, <code class="highlighter-rouge">poll</code>以及<code class="highlighter-rouge">epoll</code>函数的诞生。</p>

<p><code class="highlighter-rouge">select</code>, <code class="highlighter-rouge">poll</code>以及<code class="highlighter-rouge">epoll</code>的内容将会在未来的文章中进行详细描述， 这里只是写一个引子。</p>

<h4 id="7-小结">7. 小结</h4>
<p>在本篇文章中， 主要是通过磁盘， 网卡等硬件设备的组成， 以及DMA直接存储器的原理来对操作系统的磁盘I/O进行了梳理， 列举了一些常见的函数， 例如C标准库中的<code class="highlighter-rouge">fgets</code>， C标准库底层的<code class="highlighter-rouge">read/write</code>函数。</p>

<p>需要明确一点的是， I/O操作的确是一个非常耗时的操作， 但是这是相对于应用程序而言。 而对于操作系统而言， 通过DMA以及内存映射文件等技术手段， 已经充分利用了系统资源， 只不过在执行I/O操作时， CPU在执行其余的进程， 而并非I/O应用进程。</p>

<p>对于应用程序而言， 想要提高应用的负载能力以及运行效率， 要么采用多线程的方式使得CPU在执行某一个线程的I/O操作时进行线程切换， 执行其余线程的非I/O操作， 要么采用<code class="highlighter-rouge">select</code>, <code class="highlighter-rouge">poll</code>, <code class="highlighter-rouge">epoll</code>函数来对大量非阻塞文件或者Socket的读写进行管理。</p>


	  ]]></description>
	</item>

	<item>
	  <title>分布式系统基础学习(05)--分布式缓存设计</title>
	  <link>//distributed-cache</link>
	  <author></author>
	  <pubDate>2019-04-01T10:17:46+00:00</pubDate>
	  <guid>//distributed-cache</guid>
	  <description><![CDATA[
	     <p>在单机缓存中， 并发的安全性问题与语言的并发安全问题完全可以归为一类， 缓存的穿透问题可以采用巧妙的数据结构进行处理， 很多问题本质上仍然是一些基础问题。</p>

<!---more--->

<h4 id="1-cache-aside单机缓存模式">1. Cache Aside单机缓存模式</h4>
<p>在业务应用中， Cache Aside是最常用的缓存模式。 其主要逻辑为当请求未命中缓存时， 从DB中取出数据并将其置于缓存中， 当数据发生更新时， 删除该数据所对应的缓存。</p>

<p><img src="https://smartkeyerror.oss-cn-shenzhen.aliyuncs.com/Blog/distributed-cache/cache-aside.png" alt="" /></p>

<p>以Django框架为例， 其伪代码为:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">redis</span> <span class="o">=</span> <span class="n">Redis</span><span class="p">(</span><span class="s">"127.0.0.1"</span><span class="p">,</span> <span class="mi">6379</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">SomeView</span><span class="p">(</span><span class="n">APIView</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">get</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">request</span><span class="p">):</span>
        <span class="c"># 尝试获取缓存</span>
        <span class="n">response_data</span> <span class="o">=</span> <span class="n">redis</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s">"some_key"</span><span class="p">)</span>
        <span class="c"># 缓存未命中</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">data</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">original_data</span> <span class="o">=</span> <span class="n">SimpleModel</span><span class="o">.</span><span class="n">objects</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
                <span class="n">data</span> <span class="o">=</span> <span class="n">SimpleModelSerializers</span><span class="p">(</span><span class="n">original_data</span><span class="p">)</span><span class="o">.</span><span class="n">data</span>
                <span class="n">response_data</span> <span class="o">=</span> <span class="p">{</span><span class="s">"code"</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s">"message"</span><span class="p">:</span> <span class="s">"success"</span><span class="p">,</span> <span class="s">"data"</span><span class="p">:</span> <span class="n">data</span><span class="p">}</span>
                <span class="c"># DB数据写入缓存， 并给予15分钟的过期时间</span>
                <span class="n">redis</span><span class="o">.</span><span class="nb">set</span><span class="p">(</span><span class="s">"some_key"</span><span class="p">,</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">response_data</span><span class="p">)</span><span class="err">，</span> <span class="mi">15</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>
            <span class="k">except</span> <span class="nb">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="c"># 标准错误处理流程</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">exception</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">Response</span><span class="p">(</span><span class="n">response_data</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">SimpleModel</span><span class="p">(</span><span class="n">models</span><span class="o">.</span><span class="n">Model</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">CharField</span><span class="p">(</span><span class="n">max_length</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">force_insert</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">force_update</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">using</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
             <span class="n">update_fields</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="c"># 重写Model.save方法, 在数据更新时删除失效缓存</span>
        <span class="n">redis</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="s">"some_key"</span><span class="p">)</span>
</code></pre></div></div>

<p>这看起来似乎很简单， 而且Cache Aside模式能够最大程度的减少由于并发所带来的脏数据问题， 但是不能完全避免脏数据问题。</p>

<p><img src="https://smartkeyerror.oss-cn-shenzhen.aliyuncs.com/Blog/distributed-cache/cache-aside%E8%84%8F%E6%95%B0%E6%8D%AE%E9%97%AE%E9%A2%98.png" alt="" /></p>

<p>如上图所示， 更新请求和查询请求先后发出， 由于更新操作需要进行表单验证等步骤， 操作时间要长一些， 在还没有删除掉失效缓存之前， 查询请求就从缓存中取到了脏数据并返回了。 这种情况出现的概率比较低， 受到影响的也仅仅只有紧跟更新请求的几个查询操作。 尽管如此， 仍然需要对这种情况进行处理， 目前比较好的实现就是为缓存添加过期时间。</p>

<h4 id="2-高并发下带来的缓存问题">2. 高并发下带来的缓存问题</h4>
<p>仍然是使用Cache Aside模式进行缓存的设计， 考虑这样一个场景: 两个查询请求并发执行, 并且此时缓存中没有对应的数据， 那么两个查询请求很有可能会将缓存数据重复写入， 如下图所示:</p>

<p><img src="https://smartkeyerror.oss-cn-shenzhen.aliyuncs.com/Blog/distributed-cache/%E7%BC%93%E5%AD%98%E9%87%8D%E5%A4%8D%E5%86%99%E5%85%A5.png" alt="" /></p>

<p>2个查询请求并发执行， 缓存数据很有可能被重复写入2次。 那么N个查询请求并发执行， 缓存数据也有可能被重复的写入N次。</p>

<p>对于以json数据格式作为value的缓存数据来说， 重复写入问题也不大， 无非是将前一个结果覆盖了而已。 但是对于列表对象而言， 重复写入的问题就不得不去处理了。 列表的<code class="highlighter-rouge">lpush</code>或者是<code class="highlighter-rouge">rpush</code>操作并不会覆盖原有的数据， 而是直接追加， 这样一来就会造成严重的缓存数据重复问题，  并且多次的DB查询也会对系统整体的吞吐量造成影响。</p>

<p>限制资源的请求速率以及保证资源的唯一使用， 该怎么做？ 加锁。 在Python或者是Java语言层面， 为了保证操作的原子性以及并发安全性， 通常都会使用各种各样的互斥锁， 那么在这里也不例外， 只不过此时必须使用分布式锁。 因为Web服务要么是多进程多线程并行运行， 要么是多服务器组成的集群运行， 操作层面都在进程这一层， 只能使用分布式锁。</p>

<p>分布式锁的基本思想也很简单， 多个进程在对某个资源进行修改时， 先向第三方服务申请一下， 申请通过了才能用， 没通过就等着(轮询)。 这里无意扩展分布式锁的内容， 所以就简单的使用Redis的<code class="highlighter-rouge">setnx</code>命令实现。 此时我们只需要简单的修改一下设置缓存的部分代码即可:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 从DB中获取数据并对其进行序列化操作</span>
<span class="n">original_data</span> <span class="o">=</span> <span class="n">SimpleModel</span><span class="o">.</span><span class="n">objects</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">SimpleModelSerializers</span><span class="p">(</span><span class="n">original_data</span><span class="p">)</span><span class="o">.</span><span class="n">data</span>
<span class="n">response_data</span> <span class="o">=</span> <span class="p">{</span><span class="s">"code"</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s">"message"</span><span class="p">:</span> <span class="s">"success"</span><span class="p">,</span> <span class="s">"data"</span><span class="p">:</span> <span class="n">data</span><span class="p">}</span>


<span class="k">if</span> <span class="n">redis</span><span class="o">.</span><span class="nb">set</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s">"some_key_lock"</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="s">"1"</span><span class="p">,</span> <span class="n">ex</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">nx</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">redis</span><span class="o">.</span><span class="nb">set</span><span class="p">(</span><span class="s">"some_key"</span><span class="p">,</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">response_data</span><span class="p">)</span><span class="err">，</span> <span class="mi">15</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>
    <span class="k">except</span> <span class="nb">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">exception</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
    <span class="k">finally</span><span class="p">:</span>
        <span class="c"># 虽然对分布式锁添加了1秒的过期时间, 但是为了提高系统吞吐量, 在这里手动删除该锁</span>
        <span class="n">redis</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="s">"some_key_lock"</span><span class="p">)</span>
</code></pre></div></div>

<p>是不是这样就可以了？ 并不是， 这样写在某些情况下仍然会出现问题。 我们把两个查询操作的时间稍微错开几十毫秒， 就有可能出现下图的情况:</p>

<p><img src="https://smartkeyerror.oss-cn-shenzhen.aliyuncs.com/Blog/distributed-cache/%E7%BC%93%E5%AD%98%E9%87%8D%E5%A4%8D%E5%86%99%E5%85%A52.png" alt="" /></p>

<p>缓存数据依然被写入了两次。 其实这个问题在很多的并发场景下都会有出现， 不单单只是缓存的设计。 例如不采用枚举类所实现的单例模式， 在文章<a href="https://smartkeyerror.com/Java%E5%9F%BA%E7%A1%80%E7%BC%96%E7%A8%8B-04-%E5%B8%B8%E7%94%A8%E7%9A%84%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-01.html">Java基础编程(04)–常用的设计模式(01)</a>中采用了双重校验锁的方式解决此类问题:</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">public</span> <span class="kd">static</span>  <span class="n">SingletonClass</span> <span class="nf">getSingletonClass</span><span class="o">()</span> <span class="o">{</span>
    <span class="cm">/* 第一次校验是让实例已经被初始化之后直接返回 */</span>
    <span class="k">if</span> <span class="o">(</span><span class="n">singletonClass</span> <span class="o">==</span> <span class="kc">null</span><span class="o">)</span> <span class="o">{</span>
        <span class="cm">/* 如果此时singletonClass == null, 那么就需要线程安全的实例化对象 */</span>
        <span class="kd">synchronized</span> <span class="o">(</span><span class="n">SingletonClass</span><span class="o">.</span><span class="na">class</span><span class="o">)</span> <span class="o">{</span>
            <span class="cm">/* 再次判断, 此时为加锁判断, 保证变量不会被其它线程所修改, 即保持单例*/</span>
            <span class="k">if</span> <span class="o">(</span><span class="n">singletonClass</span> <span class="o">==</span> <span class="kc">null</span><span class="o">)</span>
                <span class="n">singletonClass</span> <span class="o">=</span> <span class="k">new</span> <span class="n">SingletonClass</span><span class="o">();</span>
        <span class="o">}</span>
    <span class="o">}</span>
    <span class="k">return</span> <span class="n">singletonClass</span><span class="o">;</span>
<span class="o">}</span>
</code></pre></div></div>

<p>在这个问题中， 依然可以使用同样的方式来处理， 即在获取分布式锁之后， 更新缓存之前， 再进行一次判断。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">if</span> <span class="n">redis</span><span class="o">.</span><span class="nb">set</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s">"some_key_lock"</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="s">"1"</span><span class="p">,</span> <span class="n">ex</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">nx</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="c"># 再次判断缓存数据是否不存在</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">redis</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s">"some_key"</span><span class="p">):</span>
            <span class="n">redis</span><span class="o">.</span><span class="nb">set</span><span class="p">(</span><span class="s">"some_key"</span><span class="p">,</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">response_data</span><span class="p">)</span><span class="err">，</span> <span class="mi">15</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>
    <span class="k">except</span> <span class="nb">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">exception</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
    <span class="k">finally</span><span class="p">:</span>
        <span class="n">redis</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="s">"some_key_lock"</span><span class="p">)</span>
</code></pre></div></div>

<h4 id="3-缓存穿透问题">3. 缓存穿透问题</h4>
<p>缓存穿透是指查询一个根本不存在的数据， 缓存层和存储层都不会命中， 而在通常情况下， 空数据是不会做缓存的， 基于Restful-API来讲， 此时应该直接返回404。 这样一来， 大量的无效请求都会透到DB存储层， 会给存储层带来比较大的压力。</p>

<p>这个问题的解决办法还是蛮多的， 最简单的就是缓存空数据。 依然使用上面的代码， 目光主要聚集在无效数据的处理上:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">try</span><span class="p">:</span>
    <span class="n">original_data</span> <span class="o">=</span> <span class="n">SimpleModel</span><span class="o">.</span><span class="n">objects</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">SimpleModelSerializers</span><span class="p">(</span><span class="n">original_data</span><span class="p">)</span><span class="o">.</span><span class="n">data</span>
    <span class="n">response_data</span> <span class="o">=</span> <span class="p">{</span><span class="s">"code"</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s">"message"</span><span class="p">:</span> <span class="s">"success"</span><span class="p">,</span> <span class="s">"data"</span><span class="p">:</span> <span class="n">data</span><span class="p">}</span>
    <span class="c"># DB数据写入缓存， 并给予15分钟的过期时间</span>
    <span class="n">redis</span><span class="o">.</span><span class="nb">set</span><span class="p">(</span><span class="s">"some_key"</span><span class="p">,</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">response_data</span><span class="p">)</span><span class="err">，</span> <span class="mi">15</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>
<span class="k">except</span> <span class="nb">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
    <span class="c"># 标准错误处理流程</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">exception</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
</code></pre></div></div>

<p>在Django中， <code class="highlighter-rouge">Model.objects.get</code>操作在数据不存在时会抛出<code class="highlighter-rouge">DoesNotExist</code>的异常， 此时就可以在异常处理中将空数据进行缓存。 遗留的问题就是如果缓存中空数据非常多的话， 非常占用服务器内存， 而且这些key是能够无限增长的。 比如网站攻击， 假如用户id最大值为1000， 而攻击方生成10亿个大于1000的id进行请求， 并限制请求速率以及使用代理服务器。 那么一段时间后服务器就会有10亿个无效数据key， 这时候内存崩没崩都不好说， 系统运行效率一定是降低的。</p>

<p>为这些key设置一个较短的过期时间(比如5秒)能够解决一部分问题， 但是总的来说还是会浪费一部分内存空间。</p>

<p>另一个解决方案就是使用Bitmap。 将所有存在的key通过哈希或者其它算法写入到Bitmap数组中， 作为第一道缓存过滤器。 当请求无效数据时， 发现Bitmap中没有这个key(时间复杂度为O(1))， 直接返回空结果即可。</p>

<p><img src="https://smartkeyerror.oss-cn-shenzhen.aliyuncs.com/Blog/distributed-cache/Bitmap%E8%BF%87%E6%BB%A4.png" alt="" /></p>

<p>只不过这种方式维护起来比较费劲， 因为需要保存所有的有效key， 如果是大规模集群缓存的话， 其复杂度以及维护成本都会相应增加。</p>

<h4 id="4-雪崩问题">4. 雪崩问题</h4>
<p>缓存雪崩问题是指当缓存层为存储层分担了绝大部分压力时， 缓存层因为服务器宕机， 网络连接异常等问题导致的崩溃， 使得所有请求全部压向存储层的现象。 此时存储层由于大量的查询而造成线程数量飙升， 连接数飙升， 内存和CPU使用率飙升， 很有可能发生系统崩溃， 导致服务大面积停机。</p>

<p>雪崩问题没有办法从代码层面去很好的解决， 只能通过高可用设计处理。 例如Redis-sentinel高可用架构， MySQL高可用架构等等， 保证系统能够及时、自动地切换节点。</p>

<h4 id="5-复制">5. 复制</h4>
<p>在分布式系统中， 由于种种原因， 例如机房故障， 负载均衡， 读写分离等， 需要将数据复制到多个副本部署到其它的机器上， 因此， Redis也提供了主从复制功能。</p>

<p>与MySQL的主从复制相比， Redis的复制功能要简单许多。 通常在主从复制的模型下， 如何发现和处理主从数据的延迟， 以及主/从节点的身份转换， 是需要我们去着重处理的。</p>

<h5 id="51-建立主从复制过程">5.1 建立主从复制过程</h5>
<p>Redis建立主从复制的方式有多种， 可以在从节点配置文件中进行配置， 也可以在从节点的客户端中进行配置。 命令只有一个:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>slaveof masterHost masterPort
</code></pre></div></div>

<h5 id="52-断开复制">5.2 断开复制</h5>
<p>断开复制的命令为<code class="highlighter-rouge">slaveof no one</code>， 在从节点执行完该命令之后， 复制过程终止， 此时从节点仍然会保留原有的数据， 但是无法获取主节点的数据变化。</p>

<p>当我们在一个从节点断开复制之后， 可以与另一个节点建立主从复制的关系， 这个过程称为”切主操作”。 如果一个从节点与当前主节点断开复制关系， 与另外一个节点建立复制关系的话， 此时从节点的数据将会被完全清空。</p>

<p>举个不恰当的例子， 某一天你在网上认了一个干妹妹， 跟她分享了很多有趣的事情。 突然有一天她不想做你妹妹了， 单方面切断了这个联系， 并删除了你的微信， 所以你更新的朋友圈她是不知道的。 然后她又找了一个新的干哥哥， 抛弃了与你所有的记忆(扎不扎心， 老铁)。</p>

<p>所以， 在生产环境的切主操作要慎重进行， 避免因操作不当带来的数据损失。</p>

<h5 id="53-复制过程">5.3 复制过程</h5>
<p>Redis主从复制过程大致可以分为:</p>
<ol>
  <li>从节点保存主节点信息</li>
  <li>从节点内部的定时任务发现新的主节点， 尝试与主节点建立连接</li>
  <li>从节点发送PING命令， 检测网络是否正常连接， 主节点是否可用</li>
  <li>权限验证</li>
  <li>首次同步时进行全量数据复制</li>
  <li>数据持续复制</li>
</ol>

<p>当主节点需要密码登录时， 从节点必须设置<code class="highlighter-rouge">masterauth</code>配置项进行密码登录。 下面贴一个在建立复制时主节点的日志记录:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1060:M 16 Mar 16:05:17.727 <span class="k">*</span> Slave 127.0.0.1:6380 asks <span class="k">for </span>synchronization
1060:M 16 Mar 16:05:17.727 <span class="k">*</span> Partial resynchronization not accepted: Replication ID mismatch <span class="o">(</span>Slave asked <span class="k">for</span> <span class="s1">'695874fc4ce12a5de99170a5751f57adf33cc032'</span>, my replication IDs are <span class="s1">'8826a80c2972c469cb65688c899b07ae249f6905'</span> and <span class="s1">'0000000000000000000000000000000000000000'</span><span class="o">)</span>
1060:M 16 Mar 16:05:17.727 <span class="k">*</span> Starting BGSAVE <span class="k">for </span>SYNC with target: disk
1060:M 16 Mar 16:05:17.727 <span class="k">*</span> Background saving started by pid 1570
1570:C 16 Mar 16:05:17.729 <span class="k">*</span> DB saved on disk
1570:C 16 Mar 16:05:17.729 <span class="k">*</span> RDB: 0 MB of memory used by copy-on-write
1060:M 16 Mar 16:05:17.771 <span class="k">*</span> Background saving terminated with success
1060:M 16 Mar 16:05:17.771 <span class="k">*</span> Synchronization with slave 127.0.0.1:6380 succeeded
</code></pre></div></div>

<p>首先就是从节点127.0.0.1:6380要求进行数据同步， 然后验证从节点的Replication ID， 来判断从节点是部分数据复制还是全量数据复制， 由于这是第一个建立复制， 所以必然是全量复制。 而后执行<code class="highlighter-rouge">BGSAVE</code>操作， fork子进程生成dump.rdb文件。 从日志上可以看出， 此时RDB文件是保存在磁盘中的， 并不是直接发送给从节点。 然后， 主节点通过网络传输， 将RDB文件发送给从节点， 从节点读取并写入数据， 复制工作就此开始。</p>

<p>当主节点的子进程开始执行BGSAVE操作时， 主节点仍然会处理写请求。 那么这部分的数据该如何处理？ Redis主节点会建立复制缓冲区， 这一段时间的数据更改都会写入复制缓冲区中， 当从节点加载完RDB文件数据之后， 主节点再将复制缓冲区的内容发送给从节点。 这样一来， 就能够保证数据的完整性。</p>

<p>如果主节点创建和传输RDB的时间过长， 对于高流量写入场景非常容易造成主节点复制缓冲区溢出， 默认配置为<code class="highlighter-rouge">client-output-buffer-limit slave 256MB 64MB 60</code>， 如果在60秒内缓冲区持续大于60MB或者超出了256MB， 主节点将主动关闭与从节点的连接， 全量复制终止。 所以， 开启从节点请选择月黑风高的凌晨。</p>

<h5 id="54-复制延迟">5.4 复制延迟</h5>
<p>在主节点和从节点分别执行<code class="highlighter-rouge">info replication</code>命令可以查看此时数据复制的偏移量。 主节点为<code class="highlighter-rouge">master_repl_offset</code>， 从节点为<code class="highlighter-rouge">slave_repl_offset</code>， 单位为字节量。 使用</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>master_repl_offset - slave_repl_offset
</code></pre></div></div>

<p>能够很轻松的计算出主从复制的延迟。 当这个延迟值很高的时候， 例如20MB， 此时应用程序就需要做出反应， 暂时性的从主节点读取数据， 当延迟降低之后， 再从从节点读取数据。</p>

<h4 id="6-redis-sentinel">6. Redis Sentinel</h4>
<p>哨兵是由Redis官方所提供的高可用架构解决方案， 实现了Redis数据节点的监控， 通知以及自动化的故障转移机制。</p>

<h5 id="61-为什么需要高可用架构">6.1 为什么需要高可用架构</h5>
<p>在一个中型服务中， Redis实例的数量可能不会特别多， 拓扑结构可能为1主1从或者是1主2从。 从库主要用于数据的读取， 主库用于数据的写入， 进行读写分离。 如果此时主节点发生宕机， 那么从节点与主节点断开连接， 复制终止， 并且应用层连接不上主节点， 无法进行数据写入， 造成服务部分功能无法使用。</p>

<p>此时要做的就是将一个从节点设置为主节点， 另一个从节点进行切主操作， 并且需要修改应用的代码， 将Redis主节点ip重新修改。 这样一套流程下来， 如果顺利的话， 也需要15分钟左右。 如果不顺利， 花费的时间将会更久。 并且人为操作还有可能出现错误， 导致数据丢失。</p>

<h5 id="62-redis-sentinel高可用性">6.2 Redis Sentinel高可用性</h5>
<p><img src="https://smartkeyerror.oss-cn-shenzhen.aliyuncs.com/Blog/distributed-cache/Sentinel.png" alt="" /></p>

<p>如上图所示， Redis Sentinel是一种分布式多机架构， 其中包含了若干个Sentinel节点以及Redis数据节点。 这里的Redis数据节点表示主节点和从节点所组成的集合。 没一个Sentinel节点都会去监控数据节点和Sentinel节点， 当发现服务不可用时， 会对其做下线标识。 如果被标记的是主节点， 那么Sentinel节点将会和其它Sentinel节点进行投票， 当大多数节点都认为主节点不可达时， 它们会推举出一个Sentinel节点来完成自动的故障转移， 并将信息通知给应用服务。</p>

<p>同样以上图为例， 当Master节点不可用并且多数Sentinel节点确认了这个事实， 并且推举Sentinel-2来进行故障转移。 Sentinel-2随机的选取一个从节点作为新的主节点，例如Slave-1， 对其发送<code class="highlighter-rouge">slaveof no one</code>命令， 终止与原有主节点的复制， 并升级为新的主节点。 接着对Slave-2节点发送<code class="highlighter-rouge">slaveof newHost newPort</code>命令， 使其从新的Master节点进行数据复制。</p>

<h4 id="7-如何对数据进行分区">7. 如何对数据进行分区</h4>
<p>在单机缓存模式下， 当我们处理了并发请求时的数据安全性， 解决了缓存穿透以及雪崩问题， 并且对缓存中big-key进行了足够好的优化之后， 剩下面临的问题就是单机内存容量的限制。</p>

<p>首先考虑一个更加具体化的问题， MySQL单表的最佳容量约为1000万数据， 也就是说， 假设有1亿数据， 那么最佳的分表方式就是将其拆分成10个表及以上。</p>

<h5 id="71-基于关键字区间">7.1 基于关键字区间</h5>

<p>一个最简单的算法就是基于关键字区间进行分区， 例如<code class="highlighter-rouge">user_id</code>。 <code class="highlighter-rouge">user_id</code>在0-1000的写入表1， <code class="highlighter-rouge">user_id</code>在1001-200万的数据写入表2， 以此类推。 这样以来能够最大程度的维护单表数据相关性， 其缺点就是为了更均匀的分布数据， 开发人员需要找到适合数据本身分布特征的分区边界。 根据2/8法则， 贡献80%数据的用户只占所有用户的20%。 所以边界如何选取， 是基于关键字区间方法的重要因素。</p>

<h5 id="72-取模算法分区">7.2 取模算法分区</h5>

<p>另一个分区算法就是根据key进行取模。 如果拆分10个表， 就使用<code class="highlighter-rouge">user_id</code>对10进行取模， 再存储到数据对应的表中。</p>

<p>取模算法一个非常致命的问题就在于水平拓展非常复杂， 只能进行垂直拓展。 在项目设计之初， 开发人员预计某一个表中的数据最多能够到达1亿， 于是拆分了20个分区表， 这样一来系统最大能够存储2亿数据。 但是系统上线后用户量日益剧增， 很早的就达到了2亿数据。 此时再对数据进行取模， 单表存储将会超过1000万。 并且， 由于数据采用取模的方式进行存储， 如果增加分区表的话， 势必会打乱原有的存储结构， Web服务也有可能停机进行数据迁移。</p>

<p>解决这个问题也很简单， 在最初设计时， 就对分区表的数量取一个较大值， 例如100。 按照单表1000万的存储， 整体存储数据量为10亿。 我相信对于绝大部分应用而言， 10亿行数据的存储量， 是完全足够的， 再加上目前SSD不值钱， 即使是1TB的固态， 也只需要1000块。 总成本在1万以内可以搞定。</p>

<p>取模算法最大的优点就在于简单， 易操作和维护， 缺点就是水平拓展困难并且数据的分布均匀性较难保证， MySQL的简单分表方式选择取模算法是一个比较好的方法， 但是对分布式缓存来说， 其中会有一些问题出现。</p>

<p>假设目前有10台Redis缓存服务器， 编号0~9， 并使用了取模方式在这10台机上进行了数据缓存。 突然3号机挂掉了， 原本属于3号机的数据服务只能被迫转移到其它机器， 例如1号机。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">if</span> <span class="n">key</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
    <span class="c"># 转至1号机服务</span>
</code></pre></div></div>

<p>现在1号机也挂了， 开发人员又不得不再去整理规则， 属于1号机的服务转移至5号机…来来回回， 数据在整体集群中非常混乱， 取模的方式很难建立一个自动化故障转移的机制来处理突发情况。</p>

<h5 id="73-一致性哈希算法分区">7.3 一致性哈希算法分区</h5>
<p>一致性哈希算法能够最大程度上自动的处理数据分布不均匀问题， 并且能够提供自动化的故障转移机制。</p>

<p>通常我们会设计一个处理字符串的32位哈希函数， 当输入某个字符串时， 它会返回一个0和2^32 - 1之间近似随机的数值。 及时输入的字符非常相似， 返回的哈希值也会在上述数字范围内均匀分布。</p>

<p>既然范围限定在0～2^32-1之间， 那么对于一个哈希值， 只能取前4个字节， 这里取md5加密的前4个字节:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">get_result</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
    <span class="k">return</span> <span class="nb">int</span><span class="p">(</span><span class="n">hashlib</span><span class="o">.</span><span class="n">md5</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">key</span><span class="p">)</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s">"utf-8"</span><span class="p">))</span><span class="o">.</span><span class="n">hexdigest</span><span class="p">()[:</span><span class="mi">8</span><span class="p">],</span> <span class="mi">16</span><span class="p">)</span>
</code></pre></div></div>

<p>将需要缓存的key进行哈希操作， 并且对缓存节点的ip地址使用同样的方法进行哈希操作， 并将其置于一个环中， 如下图左侧所示:</p>

<p><img src="https://smartkeyerror.oss-cn-shenzhen.aliyuncs.com/Blog/distributed-cache/hash-circle.png" alt="" /></p>

<p>在完成了这一部操作之后， 剩下的就是解决数据归属问题。 一致性哈希算法的思路就是找到某一个key在顺时针方向上最近的节点， 就是该key应该在的节点。 如上图所示， key1顺时针寻找， 离得最近的节点为Node1， 所以key1存储于Node1。 key2, key3存储于Node2， key4存储于Node3， key5, key6存储于Node4。</p>

<p>当我们在Node3和Node4之间新增一个节点Node5时， 受到影响的key只有Node3和Node5之间的少部分节点:</p>

<p><img src="https://smartkeyerror.oss-cn-shenzhen.aliyuncs.com/Blog/distributed-cache/add-node.png" alt="" /></p>

<p>原本key5归属于Node4， 但是由于新增节点的缘故， 在顺时针方向上离key5最近的节点为Node5， 所以key5被重新分配了。 而在缓存这个场景下， 由于key存在过期时间， 再加上缓存数据的非相关性， 系统能够快速的将这些数据重新缓存至新的节点中， 并且只有一小部分的数据会收到影响。</p>

<p>删除节点同样只会影响一小部分的数据分布。 当删除图中的Node2节点之后,  顺时针方向上离的最近的节点为Node3， 那么缓存数据将会被重新分配至Node3节点, 如下图所示:</p>

<p><img src="https://smartkeyerror.oss-cn-shenzhen.aliyuncs.com/Blog/distributed-cache/remove-node.png" alt="" /></p>

<p>有的时候系统中节点数据比较少， 在进行顺时针寻找节点时， 很有可能发生绝大多数key都去了同一个节点:</p>

<p><img src="https://smartkeyerror.oss-cn-shenzhen.aliyuncs.com/Blog/distributed-cache/%E5%88%86%E5%B8%83%E4%B8%8D%E5%9D%87%E5%8C%80.png" alt="" /></p>

<p>在系统中一种有6个缓存数据， 其中有5个数据均存储在了Node2节点， 分布非常的不均匀。 解决方法为引入虚拟节点， 其实就是将一个节点的ip， 使用字符串后缀的方法哈希多个值， 产生虚拟节点， 数据在顺时针寻找节点时如果结果是虚拟节点的话， 程序做额外的处理工作， 将其存储至虚拟节点的真实节点上。</p>

<p>假如Node3的ip为<code class="highlighter-rouge">172.15.243.16</code>， 通过添加字符串后缀的方式来添加虚拟ip， 例如<code class="highlighter-rouge">172.15.243.16@1</code>, <code class="highlighter-rouge">172.15.243.16@2</code>， 目的就是让同一个节点能够产生多个哈希值， 从而使得数据分布均匀:</p>

<p><img src="https://smartkeyerror.oss-cn-shenzhen.aliyuncs.com/Blog/distributed-cache/visual-node.png" alt="" /></p>

<p>以上就是一致性哈希算法的大致内容， 在实现上节点的存储可以采用AVL数或者是红黑树， 如果节点数量很少的话， 有序链表结构都可以。</p>

<p>一致性哈希算法在缓存设计中应用要更多一些， 一方面是因为缓存数据之间没有强关联性， 并且没有类似于关系型数据库的二级索引结构， 怎么分都可以。 更重要的是数据分布均匀性以及自动化的故障转移。</p>

<h4 id="8-一致性哈希算法的热点key问题">8. 一致性哈希算法的热点key问题</h4>
<p>虽然一致性哈希算法在引入虚拟节点后能够最大程度上的解决分区平衡问题， 但是很难处理热点数据。 一个非常极端的例子就是系统中所有缓存的读/写都是针对同一个关键字， 那么最终所有的请求都将被路由到同一个节点， 造成该节点负载急剧增加。</p>

<p>举个不恰当的例子， 微博声称目前的系统支持8位明星同时出轨(然而不能支持宣布结婚, hiahia)。 如果系统采用用户id或者是事件id作为缓存key， 几秒内的对同一个数据的读/写流量是非常巨大的。</p>

<p>热点key问题并没有一个非常好的解决方案， 只能通过应用层的scatter/gather来解决。 即对于热点的用户id或者是事件id进行随机数的添加， 将其分配至不同的分区上， 读取时再进行合并。</p>

<p>例如原本的热点key为<code class="highlighter-rouge">user_marriage_9527_list</code>, value为一个列表对象。 应用层生成[0-50)的随机数， 添加至<code class="highlighter-rouge">user_marriage_9527_list</code>的尾部， 每次的写操作都进行随机数的追加， 那么得到的key就有<code class="highlighter-rouge">user_marriage_9527_list0</code>, <code class="highlighter-rouge">user_marriage_9527_list1</code>…将这些list数据写入至不同的节点中。 在读取时， 从0到50遍历所有热点key， 结果进行合并， 去重， 返回。</p>

<p>因为读取时的额外操作， 所以通常只对极少数热点key添加随机数才有意义。</p>

<h4 id="9-小结">9. 小结</h4>
<p>分布式缓存设计是一个相当庞大的话题， 单靠一篇博文没有办法将其完整的描述， 以及对各种问题给出确切的解决方法， 所以本文也仅是在宏观角度上去分析一些最为常见的问题。</p>

<p>对于中小型服务而言， 我认为将缓存设计成为分布式并不是一个很好的选择， 能够进行垂直拓展的服务尽量先进行垂直拓展， 当垂直拓展满足不了需求之后， 再考虑分布式服务设计。</p>

	  ]]></description>
	</item>


</channel>
</rss>
